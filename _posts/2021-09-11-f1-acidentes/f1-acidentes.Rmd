---
title: "F1 Acidentes"
description: |
  A short description of the post.
author:
  - first_name: Nicholas 
    last_name: Marino
    url: https://github.com/nacmarino
date: 09-06-2021
categories:
  - tidytuesday
  - tidymodels
output:
  distill::distill_article:
    self_contained: false
    toc: true
    code_folding: true
    highlight: rstudio
draft: true
---

```{r setup, include=FALSE}
# setando as opções gerais dos code chunks
knitr::opts_chunk$set(echo = FALSE, code_folding = FALSE, fig.align = 'center', cache = TRUE)

# presetando o ggplot2
library(ggplot2)

# setando o tema geral do ggplot2
theme_set(new = theme_minimal(base_family = 'IBM Plex Sans'))

# atualizando o tema
theme_update(
  plot.title    = element_text(face = 'bold', size = 10),
  plot.subtitle = element_text(size = 8),
  plot.caption  = element_text(size = 8),
  axis.title    = element_text(face = 'bold', size = 8),
  axis.text     = element_text(color = 'black', size = 8),
  strip.text    = element_text(face = 'bold', size = 8)
)
```

# Motivação

Contentualizar o desejo de responder a pergunta.

Mostrar que existe um aumento na quantidade de intervenções de segurança.

```{r motivacao_safety_measures, layout = 'l-body-outset', dpi = 200, fig.height=5, fig.width=8, code_folding = TRUE}
# carregando os pacotes necessários
library(tidyverse) # core
# library(tidytuesdayR) # ler os arquivos do tidytuesday
library(fs) # manipular paths
library(lubridate) # trablhar com datas
library(readxl) # carregar dados de excel
library(skimr) # descricao do dataframe
library(ggupset) # para criar um upset plot
library(patchwork) # para compor figuras

# carregando os dados de dispositivos de segurança na F1
safety <- read_excel(path = 'data/f1_safety.xlsx', skip = 1)
# safety <- read_excel(path = '_posts/2021-09-11-f1-acidentes/data/f1_safety.xlsx', skip = 1)

# criando a figura principal
safety %>% 
  # prepaarando os dados para criar a figura
  mutate(
    # imputando o ano atual
    Now = year(today()),
    # ordenando as intervencoes po rano
    Intervention = fct_reorder(.f = Intervention, .x = Year, .fun = min, .desc = TRUE)
  ) %>% 
  # criando a figura do ano a partir do qual as intervenções foram implementadas
  ggplot(mapping = aes(x = Year, xend = Now, y = Intervention, yend = Intervention)) +
  geom_segment() +
  geom_point(mapping = aes(x = Year), size = 3) +
  geom_text(mapping = aes(x = Year, label = Year), nudge_x = -4, size = 3) +
  scale_x_continuous(breaks = seq(from = 1950, to = 2020, by = 10)) +
  labs(
    title    = 'Principais intervenções associadas à segurança dos pilotos ao longo dos anos',
    subtitle = 'Houve um aumento na quantidade de intervenções relacionadas à segurança entre as décadas de 90
e o início dos anos 2000.',
    caption  = 'Fonte: https://f1-insider.com/en/history-of-formula-1-safety/',
    x        = 'Ano'
  ) +
  theme(
    axis.title.y = element_blank()
  )
```

Vamos carregar o dataset do tidytuesday para analisar os acidentes.

```{r motivacao_carrega_dados}
# carregando todos os dados a partir do github do tidytuesday
# tt_dataset <- tt_load(x = 2021, week = 37) # se você quiser baixar os dados direto da fonte

# carregando a copia local dos dados
## extraindo os paths das copias locais
paths_copias_locais <- dir_ls(path = 'data/', regexp = '.rds')
# paths_copias_locais <- dir_ls(path = '_posts/2021-09-11-f1-acidentes/data/', regexp = '.rds')

## criando vetor de nomes dos arquivos
nomes_arquivos <- paths_copias_locais %>%
  path_file() %>%
  path_ext_remove()

## carregando os arquivos em uma lista
tt_dataset <- map(.x = paths_copias_locais, .f = read_rds)

## renomeando os elementos da lista
names(tt_dataset) <- nomes_arquivos
```

Precisamos juntar os resultados de cada piloto com o de-para de status para saber quantas ocorrências de acidentes têm por prova. Vou considerar 6 tipos de status para dizer que houve um acidente.

```{r motivacao_contagem_acidentes}
## adicionando o dicionario de resultados
resultados <- left_join(x = tt_dataset$results,
                        y = tt_dataset$status,
                        by = 'statusId')

## vetor com as categorias que vou usar como acidente
categorias_acidente <- c('Accident', 'Fatal accident')

## juntando padrao de regex para os acidentes
regex_acidentes <- paste0(categorias_acidente, collapse = '|')

## mapeando os acidentes por prova
acidentes_por_prova <- resultados %>% 
  # testando se aquele padrão de regex ocorre em cada linha
  mutate(tem_acidente = str_detect(string = status, pattern = regex_acidentes)) %>% 
  # agrupando as observações pelo identificador da prova
  group_by(raceId) %>% 
  # testando se existe qualquer linha onde existe algum TRUE
  summarise(tem_acidente = any(tem_acidente)) 
count(acidentes_por_prova, tem_acidente, name = 'ocorrencias')
```

A proporção de provas com acidente se mantém no mesmo patamar há algumas décadas, ainda que um número cada vez maior de medidas de segurança estejam sendo implementadas para preveni-los.

```{r serie_historica_acidentes, layout = 'l-body-outset', dpi = 200, fig.height=4, fig.width=9, code_folding = TRUE}
# calculando o volume acumulado de medidas de seguranca
acumulado_medidas <- tibble(
  # criando uma sequência completa de anos
  year = seq(from = 1950, to = 2020, by = 1)
) %>% 
  # juntando com as informacoes das medidas de seguraca por ano
  left_join(y = safety %>% 
              distinct(Year) %>% 
              mutate(medida = 1), 
            by = c('year' = 'Year')) %>% 
  # adicionando um contador zero para ajudar a fazer a soma acumulada
  replace_na(replace = list(medida = 0)) %>% 
  # calculando o volume acumulado de medidas de seguranca existentes por temporada
  mutate(n_medidas = cumsum(medida))

# criando a figura
## juntando as informacoes da ocorrencia de acidentes por prova com o ano em que a prova ocorreu
left_join(x = acidentes_por_prova,
          y = select(tt_dataset$races, raceId, year),
          by = 'raceId') %>% 
  # agrupando pela temporada
  group_by(year) %>% 
  # calculando a proporcao de provas com acidentes por temporada
  summarise(proporcao = mean(tem_acidente)) %>% 
  # juntando informacoes da quantidade acumulada de medidas de seguranca existentes por temporada
  left_join(y = acumulado_medidas, by = 'year') %>% 
  # criando a figura
  ggplot() +
  geom_line(mapping = aes(x = year, y = n_medidas / 20), color = '#3399E6', size = 1) +
  geom_line(mapping = aes(x = year, y = proporcao), color = 'tomato1', size = 1) +
  scale_x_continuous(breaks = seq(from = 1950, to = 2020, by = 10)) +
  scale_y_continuous(sec.axis = sec_axis(trans = ~ . * 20, 
                                         name = 'Quantidade de medidas de segurança existentes')) +
  labs(
    title    = 'Histórico da proporção de provas com acidente e medidas de segurança existentes por temporada',
    subtitle = 'A proporção de provas com acidente se mantém no mesmo patamar há algumas décadas, ainda que um número cada vez maior de medidas de segurança estejam sendo\nimplementadas para preveni-los.',
    x        = 'Ano/Temporada',
    y        = 'Proporção de provas com acidente na temporada'
  ) +
  theme(
    axis.title.y.left  = element_text(colour = 'tomato1'),
    axis.text.y.left   = element_text(colour = 'tomato1', face = 'bold'),
    axis.title.y.right = element_text(colour = '#3399E6'),
    axis.text.y.right = element_text(colour = '#3399E6', face = 'bold')
  )
```

# Preparação dos Dados

Explicar que preciso levantar as informações ao nível de cada prova, considerando informações que saberemos de antemão. Falar que as variáveis que vou utilizar são baseadas em algumas hipóteses que tenho, e que apresento enquanto explicar.

Começar por um combo de três hipóteses: tempo durante a prova, o tipo de circuito e a extensão do circuito. 

Falar que consegui as informações raspando a wikipedia através de informações disponíveis nos próprios dados. Aproveitar para exemplificar o caso em que não dá para usar informação _a posteriori_ usando a variável de distancia.

```{r fe_weather, code_folding = FALSE}
tempo_durante_prova <- tt_dataset$weather_and_other %>% 
  # removendo a coluna de voltas, pois ja temos ela na base de dados
  select(-voltas) %>% 
  # agrupando operacao seguinte linha a linha
  rowwise(raceId) %>% 
  # ajustando features relacionadas ao tempo durante a prova
  mutate(
    # flag para quando a informação estiver indisponivel
    ausente = as.numeric(is.na(sum(c_across(nublado:quente)))),
    # flag para quando o tempo nao for nenhuma das outras alternativas 
    outro   = as.numeric(sum(c_across(nublado:quente)) == 0)
  ) %>%
  # desagrupando a estrutura rowwise da tabela
  ungroup() %>% 
  # preenchendo os NAs com 0 apenas nas colunas com as flags do tempo durante a prova
  mutate(across(nublado:outro, replace_na, 0))
rmarkdown::paged_table(x = tempo_durante_prova)
```

Hipótese seguinte tem haver com o estado da disputa entre os pilotos.

```{r fe_points, code_folding = FALSE}
## juntando as informacoes das provas com a pontuacao por piloto por prova, round e temporada
disputa_por_prova <- left_join(x = tt_dataset$driver_standings,
                               y = select(tt_dataset$races, raceId, year, round),
                               by = 'raceId') %>% 
  # organizando pontuação por ano e prova em ordem decrescente, da primeira à última prova
  arrange(year, round, desc(points)) %>% 
  # agrupando por ano e prova
  group_by(year, raceId) %>% 
  # criando uma mascara para nos ajuda a calcular as metricas apenas considerando a pontuacao
  # dos pilotos no topo do ranking da temporada por prova e ano
  mutate(
    mask_positions = ifelse(test = row_number() <= 5, yes = 1, no = NA)
  ) %>%
  # sumarizando metricas para representar força da disputa à cada prova e ano
  summarise(
    # coeficiente de variação da pontuação dos cinco pilotos com mais pontos à cada prova 
    # concluída em cada temporada
    cv_top_pilots = sd(points * mask_positions, na.rm = TRUE) / mean(points * mask_positions, na.rm = TRUE),
    # coeficiente de variação da pontuação de todos os pilotos à cada prova concluída em cada temporada
    cv_all_pilots = sd(points) / mean(points), 
    .groups = 'drop'
  ) %>% 
  # garantindo ordenamento por ano e prova
  arrange(year, raceId) %>% 
  # agrupando por ano
  group_by(year) %>% 
  # imputando o coeficiente de variacao das metricas da corrida prova anterior para prever o resultado
  # da corrida atual - não dá para usar o dado de uma informação obtida após a prova para prever o que 
  # acontecerá durante a prova
  mutate(cvl_top_pilots = lag(cv_top_pilots), cvl_all_pilots = lag(cv_all_pilots)) %>% 
  # dropando o grupo
  ungroup %>% 
  # substituindo os NAs por zero - no inicio de cada temporada não houve nenhuma prova anterior e, 
  # portanto vamos assumir que não há uma competição intensa neste momento
  replace_na(replace = list(cvl_top_pilots = 0, cvl_all_pilots = 0)) %>% 
  # dropando a coluna de ano
  select(-year)
rmarkdown::paged_table(x = disputa_por_prova)
```

Outras hipóteses que temos: quantidade de competidores, quantidade de voltas e informações de calendário.

```{r fe_outras_features, code_folding = FALSE}
## quantidade de pilotos e construtores por prova
participantes_por_prova <- resultados %>% 
  # pegando os valores unicos das chaves primarias por prova
  distinct(raceId, driverId, constructorId) %>% 
  # agrupando por prova
  group_by(raceId) %>% 
  # quantidade de pilotos e construtores por prova
  summarise(
    n_pilotos      = n_distinct(driverId),
    n_construtores = n_distinct(constructorId)
  )

## calculando a quantidade de voltas em cada prova
voltas_por_prova <- resultados %>% 
  # considerando apenas os pilotos que concluiram cada prova
  filter(status == 'Finished') %>% 
  # selecionando as colunas de interesse
  select(raceId, laps) %>% 
  # pegando o valor maximo da quantidade de voltas por prova
  group_by(raceId) %>% 
  summarise(laps = max(laps))

## mapeando cada circuito à uma prova
provas <- left_join(x = tt_dataset$races,
                    y = tt_dataset$circuits,
                    by = 'circuitId') %>% 
  # removendo URL da wikipedia
  select(-contains('url'), -circuitRef, -circuitId, -round) %>%
  # renomeando o nome do GP e do circuito
  rename(gp = name.x, circuit = name.y) %>% 
  # levantando informacoes de data
  mutate(
    data     = paste(date, time),
    data     = as_datetime(data),
    mes      = month(data),
    semana   = isoweek(x = data),
    turno_pm = pm(data),
    decada   = (year %/% 10) * 10
  ) %>% 
  select(-date, -time)
```

Features calculadas, vamos consolidar elas em uma base só.

```{r junta_features_por_prova, code_folding = FALSE}
## juntando informacoes das provas com a quantidade de participantes e construtores
features_por_prova <- left_join(x = provas,
                             y = participantes_por_prova,
                             by = 'raceId') %>% 
  ## juntando de voltas por prova
  left_join(y = voltas_por_prova, by = 'raceId') %>% 
  ## juntando informacoes da intensidade da disputa
  left_join(y = disputa_por_prova, by = 'raceId') %>% 
  ## juntando informacoes do tempo em cada prova
  left_join(y = tempo_durante_prova, by = 'raceId')
rmarkdown::paged_table(x = features_por_prova)
```

Consolidando a base analítica.

```{r cria_base_analitica, code_folding = FALSE}
df <- left_join(x = acidentes_por_prova, y = features_por_prova, by = 'raceId')
rmarkdown::paged_table(x = df)
```

# Análise Exploratória

Visão geral dos dados que temos no dataframe.

```{r skim_da_base_analitica, layout = 'l-body-outset'}
skim(data = df)
```

Valores missing que sabemos quais são.

```{r imputa_missing}
df <- df %>% 
  # as instancias que faltam a informacao do tipo de circuito sao todos de autodromos oficiais
  # que nao estao sendo mais usados pela F1
  replace_na(replace = list(permanent_circuit = 1, street_circuit = 0, temporary_circuit = 0))
```

Acidentes são mais frequentes em alguns meses do ano, mas sem padrão claro.

```{r acidentes_por_mes, layout = 'l-body-outset', dpi = 200, fig.height = 4, fig.width = 7, code_folding = TRUE}
# criando a figura da propoção de provas com acidentes por mes
df %>% 
  # criando coluna com o mes por extenso em portugues
  mutate(mes_str = month(x = data, label = TRUE, locale = 'pt_BR', abbr = FALSE)) %>% 
  # agrupando pelo mes
  group_by(mes_str) %>% 
  # calculando a proporcao de provas com acidentes por mes
  summarise(proporcao = mean(tem_acidente)) %>% 
  # plotando a figura
  ggplot(mapping = aes(x = mes_str, y = proporcao, fill = proporcao)) +
  geom_col(color = 'black') +
  geom_text(mapping = aes(label = round(x = proporcao, digits = 2)), nudge_y = 0.06) +
  scale_fill_fermenter(type = 'div', palette = 'RdBu', direction = -1) +
  coord_polar() +
  labs(
    title = 'Proporção de provas com acidente por mês no histórico',
    caption  = 'Quanto mais quente o gradiente de cor, mais frequentes são os acidentes naquele mês.'
    ) +
  theme(
    legend.position = 'none',
    axis.text.y     = element_blank(),
    axis.title      = element_blank()
    )
```

Acidentes são certos em alguns circuitos, mas nem tanto em outros.

```{r acidentes_por_circuito, layout = 'l-body-outset', dpi = 200, fig.height=8, fig.width = 9, code_folding = TRUE}
df %>% 
  # codificando circuitos infrequentes como classe a parte
  mutate(circuit = fct_lump_min(f = circuit, min = 4)) %>%
  # agrupando no circuito
  group_by(circuit) %>% 
  # calculando a proporcao de provas com acidente
  summarise(
    proporcao = mean(tem_acidente), 
    obs       = n(),
    .groups = 'drop'
  ) %>% 
  # reordenando os niveis do circuito
  mutate(
    circuit = fct_reorder(.f = circuit, .x = proporcao)
  ) %>% 
  # criando a figura
  ggplot(mapping = aes(x = proporcao, y = circuit, fill = proporcao)) +
  geom_col(color = 'black') +
  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.2), limits = c(0, 1)) +
  scale_fill_distiller(type = 'div', palette = 'RdBu') +
  labs(
    title    = 'Proporção das provas com acidente em cada circuito',
    subtitle = 'Existem registros de acidentes em todas as provas que ocorreram em alguns circuitos.',
    caption  = 'Quanto mais quente o gradiente de cor, mais frequentes são os acidentes naquele circuito.',
    x        = 'Proporção de provas com acidente'
  ) +
  theme(
    legend.position = 'none',
    axis.title.y = element_blank()
  )
```

Tipo de circuito parece interferir na ocorrência dos acidentes.

```{r acidente_por_tipo_circuito, layout = 'l-paged', dpi = 200, fig.height=4, fig.width=8, code_folding = TRUE}
df %>% 
  # pegando apenas o target e o tipo de circuito
  select(tem_acidente, raceId, ends_with('_circuit')) %>% 
  # passando a base para o formato longo, de forma a facilitar a criacao da figura
  pivot_longer(names_to = 'tipo_circuito', values_to = 'valor', cols = contains('circuit')) %>%
  # removendo os casos negativos
  filter(valor != 0) %>% 
  # recodificando o tipo de circuito por corrida
  group_by(raceId) %>% 
  summarise(
    # juntando a string de diferentes tipos de circuito para uma mesma corrida
    tipo_circuito = paste0(tipo_circuito, collapse = "_"),
    # ajustando a string
    tipo_circuito = case_when(
      tipo_circuito == 'street_circuit_temporary_circuit' ~ 'Temporary Street Circuit',
      TRUE ~ str_to_title(string = str_replace(string = tipo_circuito, pattern = '_', replacement = ' '))
    ),
    # pegando uma unica ocorrencia do target
    tem_acidente = any(tem_acidente)) %>% 
  # agrupando pelo tipo de circuito
  group_by(tipo_circuito) %>% 
  # calculando a proporcao de acidentes
  summarise(proporcao = mean(tem_acidente), .groups = 'drop') %>% 
  # reordenando os niveis do tipo de circuito
  mutate(tipo_circuito = fct_reorder(.f = tipo_circuito, .x = proporcao, .desc = TRUE)) %>% 
  # criando a figura
  ggplot(mapping = aes(x = tipo_circuito, y = proporcao, fill = proporcao)) +
  geom_col(color = 'black', width = 0.8) + 
  geom_text(mapping = aes(label = round(x = proporcao, digits = 3)), size = 3, nudge_y = 0.03) +
  scale_fill_distiller(type = 'div', palette = 'RdBu') +
  scale_y_continuous(breaks = seq(from = 0, to = 0.8, by = 0.2), limits = c(0, 0.81)) +
  labs(
    title    = 'Proporção de provas com acidente por tipo de circuito',
    subtitle = 'Uma menor proporção de acidentes ocorreu em provas em autódromos quando comparado àquelas em circuitos temporários e/ou de rua.',
    caption  = 'Quanto mais quente o gradiente de cor, mais frequentes são os acidentes naquele tipo de circuito.',
    x        = 'Tipo de circuito',
    y        = 'Proporção de acidentes registados'
  ) +
  theme(
    legend.position = 'none'
  )
```

Intensidade da disputa também parece colaborar para a ocorrência de acidentes.

```{r acidentes_por_forca_competicao, layout = 'l-body-outset', dpi = 200, fig.height=5, fig.width=8, code_folding = TRUE}
df %>% 
  # parseando o vetor logico do target para numerico
  mutate(tem_acidente = as.numeric(tem_acidente)) %>% 
  # removendo as observacoes do inicio da temporada - aquelas com o lag das metricas igual a 0
  filter(cvl_top_pilots > 0) %>% 
  # criando a figura
  ggplot(mapping = aes(x = cvl_top_pilots, y = cvl_all_pilots, color = tem_acidente)) +
  stat_bin_2d(bins = 20) +
  scale_fill_distiller(type = 'div', palette = 'RdBu', 
                       guide = guide_colorbar(title = 'Acidentes')) +
  scale_y_continuous(breaks = seq(from = 0, to = 3.5, by = 0.25)) +
  labs(
    title    = 'Intensidade da disputa e ocorrência de acidentes',
    subtitle = 'Um coeficiente de variação menor que 1 sugere que a diferença na pontuação dos pilotos é pequena e, portanto, seria indicativa 
de uma maior intensidade da disputa pelo campeonato.',
    caption  = 'Quanto mais quente o gradiente de cor, mais frequentes são os acidentes naquela condição de disputa.',
    x        = 'Coeficiente de variação na pontuação dos cinco pilotos no topo do ranking',
    y        = 'Coeficiente de variação na pontuação de todos os pilotos'
  )
```

Clima durante a prova.

```{r acidentes_por_tempo, layout = 'l-body-outset', dpi = 200, fig.height=7, fig.width=10, code_folding = TRUE}
# acidentes por combinacao de condicao climatica
fig_1 <- df %>% 
  # pegando apenas as colunas de identificador das provas e da condicao do tempo durante a prova
  select(raceId, tem_acidente, nublado:outro) %>% 
  # passando a base para o formato longo
  pivot_longer(cols = -c(raceId, tem_acidente), names_to = 'tempo', values_to = 'valor') %>% 
  # removendo as linhas com as condicoes do tempo que nao ocorreram durante cada prova
  filter(valor > 0) %>% 
  # agrupando pela prova
  group_by(raceId) %>% 
  # juntanto a condicao do tempo em uma string so por prova
  summarise(
    tem_acidente = any(tem_acidente),
    tempo        = paste0(sort(tempo), collapse = '-')
  ) %>% 
  # agrupando pela condicao do tempo especifica
  group_by(tempo) %>% 
  # calculando a proporcao de acidentes associada à cada condicao do tempo especifica
  summarise(
    proporcao = mean(tem_acidente), 
    .groups = 'drop'
  ) %>% 
  # reorganizando a variavel de condicao do tempo para a figura
  mutate(
    tempo = str_to_title(string = tempo),
    tempo = fct_reorder(.f = tempo, .x = proporcao, .fun = min, .desc = TRUE)
  ) %>% 
  # criando a figura
  ggplot(mapping = aes(x = tempo, y = proporcao, fill = proporcao)) +
  geom_col(color = 'black', size = 0.5, show.legend = FALSE) +
  axis_combmatrix() +
  scale_fill_distiller(type = 'div', palette = 'RdBu') +
  scale_y_continuous(breaks = seq(from = 0, to = 1, by = 0.2)) +
  labs(
    x        = 'Condição do tempo',
    y        = 'Proporção de provas com acidente'
  )

# acidentes por tipo unico de condicao do tempo
fig_2 <- df %>% 
  # pegando apenas as colunas de identificador das provas e do tempo durante a prova
  select(raceId, tem_acidente, nublado:outro) %>% 
  # passando a base para o formato longo
  pivot_longer(cols = -c(raceId, tem_acidente), names_to = 'tempo', values_to = 'valor') %>% 
  # removendo as linhas com tempos que nao ocorreram durante cada prova
  filter(valor > 0) %>% 
  # agrupando pela condicao do tempo
  group_by(tempo) %>% 
  # calculando a proporcao de acidentes associada à cada condicao do tempo generica
  summarise(
    proporcao = mean(tem_acidente), 
    .groups = 'drop'
  ) %>% 
  # reorganizando a variavel de condicao do tempo para a figura
  mutate(
    tempo = str_to_title(string = tempo),
    tempo = fct_reorder(.f = tempo, .x = proporcao, .fun = min, .desc = FALSE)
  ) %>% 
  # criando a figura
  ggplot(mapping = aes(x = tempo, y = proporcao, fill = tempo)) +
  geom_col(color = 'black', show.legend = FALSE, size = 0.5) +
  geom_text(mapping = aes(label = round(x = proporcao, digits = 3)), nudge_y = -0.1, size = 3) +
  scale_fill_brewer(type = 'div', palette = 'RdBu', direction = -1) +
  scale_y_continuous(breaks = seq(from = 0, to = 1, by = 0.25)) +
  theme(axis.title = element_blank()) +
  coord_flip()

# compondo a figura
fig_1 + 
  fig_2 +
  plot_layout(
    design = c(
      area(t = 1, l = 1, b = 5, r = 4),
      area(t = 1, l = 4, b = 2, r = 5)
    )
  ) +
  plot_annotation(
    title    = 'Proporção de provas com acidentes de acordo com a condição do tempo',
    subtitle = 'O gráfico principal mostra a proporção de provas em que houve um acidente que estão associadas à uma condição do tempo específica, enquanto o inset traz as mesmas informações mas focando\nnas 9 condições do tempo organizadas de forma mais genérica.',
    caption  = 'Quanto mais quente o gradiente de cor, mais frequentes são os acidentes nas provas que apresentam àquela condição do tempo.'
  )
```

# Análise dos Dados

## Definição das métricas

Explica racional.

```{r define_metricas}
# carregando os pacotes para a analise de dados
library(tidymodels) # core para ajustar os modelos
library(finetune) # selecao de hiperparametros

# definindo as tres metricas que vamos monitorar: log loss, AUC e especificidade
metricas <- metric_set(roc_auc, mn_log_loss, sensitivity)
```

## Separação dos dados

Separa em treino e teste.

```{r train_test_split}
# passando o target para um fator e a variavel de turno para numerico
df <- mutate(df, 
             tem_acidente = as.factor(ifelse(test = tem_acidente, yes = 1L, no = 0L)),
             turno_pm     = as.numeric(turno_pm)
)

# definindo a seed para a reprodutibilidade
set.seed(64)
# fazendo o split da base em treino e teste
train_test_split <- initial_split(data = df, prop = 0.75, strata = tem_acidente)
train_test_split
```

Separa para a validação cruzada.

```{r cross_val_split}
# definindo a seed para a reprodutibilidade
set.seed(128)
# criando o esquema para a validação cruzada
kfold <- vfold_cv(data = training(x = train_test_split), v = 5, strata = tem_acidente)
kfold
```

## Preparação dos dados

```{r cria_receita}
pre_processamento <- recipe(tem_acidente ~ ., data = training(x = train_test_split)) %>%
  # passando a raceId para a role de id da base
  update_role(raceId, new_role = 'id') %>%
  # adicionando o mes
  step_date(data, features = 'month', abbr = FALSE) %>% 
  # removendo as colunas que nao sao necessarias para a modelagem
  step_rm(c(gp, location:data, semana, distancia, decada, 
            cv_top_pilots, cv_all_pilots, n_construtores, mes)) %>%
  # criando um step para associar circuitos nao vistos a um novo valor
  step_novel(circuit) %>%
  # agrupando circuitos menos frequentes
  step_other(circuit, threshold = 5, other = 'Other') %>%
  # fazendo o one hot encoding dos circuitos
  step_dummy(circuit, data_month, one_hot = FALSE)
pre_processamento
```

## Definição do baseline

### Naive

```{r baseline_naive}
kfold %>% 
  # extraindo o target a partir de cada fold
  mutate(
    obs_target = map(.x = splits, .f = ~ training(.x) %>% pull(tem_acidente))
  ) %>% 
  # pegando so o id do fold e a list column com o target
  select(id, obs_target) %>% 
  # desempacotando os targets
  unnest(obs_target) %>% 
  # criando colunas com a previsao naive a fim de definir um baseline sem um modelo
  # nesse caso, vamos sempre prever que ocorrera um acidente em cada prova, independentemente
  # de qualquer informacao que tenhamos sobre elas
  mutate(
    # criando um target numerico para que ele seja usado para calcular o auc e log loss
    prd_target_num = 1, 
    # criando um target no formato fator para calcular a especificidade
    prd_target_fct = factor(x = 1L, levels = c(0L, 1L)),
    # target
  ) %>% 
  # agrupando pelo id do fold
  group_by(id) %>% 
  # calculando cada uma das metricas para cada fold
  summarise(
    log_loss       = mn_log_loss_vec(truth = obs_target, estimate = prd_target_num),
    auc            = roc_auc_vec(truth = obs_target, estimate = prd_target_num),
    especificidade = specificity_vec(truth = obs_target, estimate = prd_target_fct),
    .groups = 'drop'
  )
```

### Modelo

blablabla

```{r baseline_modelo}
# cria uma instancia do algoritmo com valores default
algoritmo_baseline <- rand_forest() %>%
  set_engine(engine = 'ranger', importance = 'impurity') %>%
  set_mode(mode = 'classification')

# define um workflow com a receita do pre-processamento e o algoritmo
wf_baseline <- workflow() %>% 
  add_recipe(recipe = pre_processamento) %>% 
  add_model(spec = algoritmo_baseline)

# setando a seed para a reprodutibilidade
set.seed(256)

# ajusta o workflow do baseline aos folds
fit_baseline <- wf_baseline %>% 
  fit_resamples(resamples = kfold, 
                metrics = metricas, 
                control = control_resamples(verbose = TRUE, allow_par = TRUE)
  )

# extrai as metricas do baseline
collect_metrics(x = fit_baseline)
```

## Preparação do algoritmo

blablabla

```{r tuning_algoritmo}
# cria uma instancia do algoritmo com hiperparametros a serem tunados
algoritmo_tuning <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine(engine = 'ranger', importance = 'impurity') %>%
  set_mode(mode = 'classification')
```

blablabla

```{r tuning_finaliza_hiperparametros}
hiperparametros <- parameters(algoritmo_tuning) %>% 
  update(mtry = mtry(range = c(1L, 25L)))
```

blablabla

```{r tuning_workflow}
# define um workflow com a receita do pre-processamento e o algoritmo para ser tunado
wf_tuning <- workflow() %>% 
  add_recipe(recipe = pre_processamento) %>% 
  add_model(spec = algoritmo_tuning)
```

## Seleção de hiperparâmetros

blablabla

```{r tuning_hiperparametros}
# setando a seed para a reprodutibilidade
set.seed(512)

# ajusta o workflow do baseline aos folds
fit_tuning <- wf_tuning %>% 
  tune_sim_anneal(
    resamples  = kfold,
    metrics    = metricas,
    param_info = hiperparametros,
    iter       = 50,
    initial    = 10,
    control    = control_sim_anneal(verbose = TRUE, restart = 5)
  )
```

blablabla

```{r tuning_autoplot, layout = 'l-body-outset', dpi = 200, fig.height=7, fig.width=10, code_folding = TRUE}
# hiperparametros utilizados por iteracao
params <- autoplot(object = fit_tuning, metric = 'roc_auc', type = 'parameters') +
  labs(y = 'Valor do hiperparâmetro') +
  theme(axis.title.x = element_blank())
# evolucao da performance por iteracao
perf <- autoplot(object = fit_tuning, metric = 'roc_auc', type = 'performance') +
  labs(x = 'Iteração', y = 'AUC')
# compondo o plot
(params / perf) +
  plot_annotation(title = 'Evolução da seleção de hiperparâmetros por iteração do Simulated Annealing',
                  tag_levels = 'A')
```

blablabla

```{r tuning_melhores}
show_best(x = fit_tuning, metric = 'roc_auc', n = 5)
```

blablabla

```{r diferenca_tuning_baseline, code_folding = TRUE}
# pegando o resultado do AUC do baseline
baseline <- collect_metrics(x = fit_baseline) %>% filter(.metric == 'roc_auc')
# pegando as metricas do melhor modelo tunado
tuned_results <- show_best(x = fit_tuning, metric = 'roc_auc', n = 1)

# pre-calculando o quadrado dos erros padroes
se_baseline <- baseline$std_err^2
se_tuned <- tuned_results$mean^2

# extraindo a quantidade de observacoes (igual para os dois)
n_obs <- baseline$n

# calculando a estatística t da diferenca entre as medias
estatistica <- (baseline$mean - tuned_results$mean) / sqrt((se_baseline + se_tuned))

# numero de graus de liberdade ajustado
df_welch <- ((se_baseline + se_tuned)^2) / ((se_baseline^2/(n_obs - 1)) + (se_tuned^2/(n_obs - 1)))

# calculando o p-valor associado a estatistica
p_valor <- 2 * pt(q = estatistica, df = df_welch, lower.tail = TRUE)

# printando o resultado
sprintf(fmt = 'Estatistica t: %.3f | df: %.2f| p-valor: %5f', estatistica, df_welch, p_valor)
```

## Ajuste do modelo selecionado

blablabla

```{r last_fit_baseline}
## ajustando o modelo aos dados uma ultima vez
modelo_ajustado <- last_fit(object = wf_baseline, split = train_test_split, metrics = metricas)

## pegando as metricas do modelo
collect_metrics(x = modelo_ajustado)
```

blablabla

```{r matriz_confusao_normal, dpi = 200, fig.height=4, fig.width=5, code_folding = TRUE}
# pegando as previsoes do modelo ajustado
collect_predictions(x = modelo_ajustado) %>% 
  # tabulando as previsoes e observacoes
  count(tem_acidente, .pred_class) %>% 
  # ajustando o texto das previsoes e target
  mutate(across(where(is.factor), \(x) ifelse(test = x == 1, yes = 'Sim', no = 'Não'))) %>% 
  # recodificando o nivel dos fatores
  mutate(
    tem_acidente = fct_relevel(.f = tem_acidente, 'Sim'),
    .pred_class = fct_relevel(.f = .pred_class, 'Não')
  ) %>% 
  # criando a figura
  ggplot(mapping = aes(x = .pred_class, y = tem_acidente, fill = n, label = n)) +
  geom_tile(color = 'black', show.legend = FALSE) +
  geom_text(fontface = 'bold', size = 4) +
  scale_fill_viridis_c(begin = 0.3) +
  labs(
    title    = 'Previsões feitas pelo modelo vs ocorrência dos acidentes',
    subtitle = 'A matriz de confusão apresenta os acertos no modelo na diagonal principal e os\nerros na diagonal oposta.',
    x        = 'Previsão de acidente?',
    y        = 'Ocorreu o acidente?'
  )
```

## Explicabilidade

blablabla

```{r importancia_variaveis, layout = 'l-body-outset', dpi = 200, fig.height=5, fig.width=8, code_folding = TRUE}
# pegando o modelo ajustado
extract_fit_parsnip(x = modelo_ajustado) %>% 
  # extraindo a importancia das variaveis de dentro do objeto do modelo
  pluck('fit', 'variable.importance') %>% 
  # colocando o vetor nomeado em uma dataframe
  enframe(name = 'variavel', value = 'importance') %>% 
  # pegando as 15 variaveis mais importantes
  top_n(n = 15, wt = importance) %>% 
  # reordenando as variaveis para plotar
  mutate(
    variavel = str_remove(string = variavel, pattern = 'circuit_'),
    variavel = str_replace_all(string = variavel, pattern = '(_|\\.)', replacement = ' '),
    variavel = str_to_title(string = variavel, locale = 'pt_BR'),
    variavel = fct_reorder(.f = variavel, .x = importance, .desc = FALSE)
  ) %>% 
  # criando a figura
  ggplot(aes(x = importance, y = variavel)) +
  geom_col(aes(fill = importance), color = 'black') +
  geom_text(aes(label = round(importance, 2)), nudge_x = 3) +
  scale_fill_viridis_c(begin = 0.1) +
  scale_x_continuous(breaks = seq(from = 0, to = 50, by = 10)) +
  labs(title    = 'Importância das variáveis para o modelo',
       subtitle = 'As 15 variáveis mais importantes de acordo com o critério de impureza de Gini') +
  theme(
    legend.position = 'none',
    axis.title = element_blank()
  )
```

blablabla

```{r instancia_dalex}
# carregando o pacote
library(DALEX)
library(DALEXtra)

# criando instancia do DALEX para explicar o modelo
explainer <- explain_tidymodels(
  extract_workflow(x = modelo_ajustado), 
  data = training(train_test_split) %>% select(-tem_acidente),
  y = as.integer(training(train_test_split)$tem_acidente)
)
```

blablalba

```{r pdp_dalex, layout = 'l-body-outset', dpi = 200, fig.height=4, fig.width=10, code_folding = TRUE}
# pegando os dados do partial dependence plot
model_profile(
  explainer = explainer, 
  variables = c('year', 'cvl_all_pilots', 'cvl_top_pilots'), 
  type = 'partial'
) %>%
  # extraindo os dados para criar a figura no ggplot
  pluck('agr_profiles') %>% 
  # ajustando a ordem dos graficos
  mutate(
    `_vname_` = case_when(`_vname_` == 'cvl_top_pilots' ~ 'CV pontuação dos cinco pilotos no topo do ranking',
                          `_vname_` == 'cvl_all_pilots' ~ 'CV pontuação de todos os pilotos',
                          TRUE ~ 'Ano')
  ) %>% 
  # criando a figura
  ggplot(mapping = aes(x = `_x_`, y = `_yhat_`)) +
  facet_wrap(~ `_vname_`, scales = 'free', strip.position = 'bottom') +
  geom_line() +
  labs(
    title    = 'Efeitos parciais de três variáveis sobre a probabilidade de ocorrência de acidentes',
    subtitle = 'O efeito parcial de uma variável sobre a resposta é aquele medido variando apenas à variável de interesse e fixando-se todas as demais',
    y        = 'Probabilidade de ocorrência de um acidente'
  ) +
  theme(axis.title.x = element_blank())
```

# Conclusão

# Possíveis Extensões