---
title: "Qual a diferença entre júnior, pleno e sênior? Uma abordagem baseada em dados"
description: |
  A short description of the post.
author:
  - first_name: Nicholas 
    last_name: Marino
    url: https://github.com/nacmarino
date: 12-31-2022
categories:
  - reticulate
  - python
  - data science
output:
  distill::distill_article:
    self_contained: true
    toc: true
    code_folding: true
    fig_retina: 1
    highlight: rstudio
draft: true
---

```{r setup, include=FALSE}
# setando as opções gerais dos code chunks
knitr::opts_chunk$set(echo = FALSE, code_folding = TRUE, cache = TRUE, dpi = 200, fig.showtext = TRUE, fig.align = 'center')

# carregando o showtext para pegar novas fontes
library(showtext)

# baixando as fontes que vamos usar
font_add_google(name = 'IBM Plex Sans', family = 'ibm')

# adicionando fonte automaticamente aos plots gerados
showtext_auto()

# presetando o ggplot2
library(ggplot2)

# setando o tema geral do ggplot2
theme_set(new = theme_minimal(base_family = 'ibm'))

# atualizando o tema
theme_update(
  panel.grid    = element_blank(),
  plot.title    = element_text(face = 'bold', size = 14),
  plot.subtitle = element_text(size = 10),
  plot.caption  = element_text(size = 9),
  axis.title.x  = element_text(face = 'bold', size = 12, margin = margin(t = 10)),
  axis.title.y  = element_text(face = 'bold', size = 12, margin = margin(r = 10)),
  axis.text     = element_text(color = 'black', size = 10),
  axis.line     = element_line(color = 'black'),
  strip.text    = element_text(face = 'bold', size = 12)
)

# definindo o um vetor com o codigo hex da paleta de cores do data hackers
cores_data_hackers <- c('#7037FF', '#7511A6', '#3B0053')
```

# O que faz a senioridade de um profissional de dados?

Existe um debate bastante ativo na comunidade de dados sobre o perfil de profissionais em nível de carreira Júnior, Pleno e Sênior. Alguns motivos para isso já foram explorados exaustivamente em posts de [blog](www.google.com), canais do [YouTube](https://www.youtube.com/watch?v=GdfJWFru5rs) e [podcasts](https://medium.com/data-hackers/o-senior-de-hoje-%C3%A9-o-staff-de-amanh%C3%A3-staff-podcast-02-db4c02839284), mas dois parecem se destacar muitas vezes onde se fala sobre o tema. O primeiro deles é o fato do mercado de dados estar bastante aquecido, de forma que o nível de senioridade em um cargo passou a ser uma moeda de troca para reter ou atrair as pessoas profissionais de dados. Já o segundo destes motivos é bem mais simples: ainda falta alguma clareza sobre o que realmente os diferencia: forma de atuar, entregar, conhecimento e/ou impacto (e em que combinação destas coisas)? Assim, ainda há a necessidade de entender um pouco melhor sobre a atuação dos profissionais em cada um daqueles níveis de carreira e o que os diferencia.

Uma forma de tentar contribuir para uma resolução do debate sobre a diferença entre as pessoas profissionais de dados de acordo com o nível de carreira está no desenvolvimento de [check-lists de atuação](littleblah.com/post/2019-09-01-senior-engineer-checklist/) e [matrizes de competência](https://sijinjoseph.com/programmer-competency-matrix/). Estas ferramentas são bastante atrativas pois elas nos permitem identificar rapidamente e claramente o que devemos fazer para progredir na carreira, facilitando o desenvolvimento de planos de ação mais objetivos. Um exemplo ilustrativo disso está na associação entre o aumento na profundidade e/ou horizontalidade do conhecimento técnico sobre a progressão de carreira para os níveis mais Sênior, o que pode ser facilmente obtido fazendo alguns cursos online e estudando. Por outro lado, diferenças na realidade das pessoas profissionais de dados e das empresas em que trabalham podem fazer com que algumas daquelas ferramentas simplesmente não se encaixem tão bem. Um caso no qual isto pode ocorrer é aquele de profissionais que atuam em ramos distintos na área de dados (_e.g._, consultorias e pesquisa acadêmica), no qual os tipos de _soft_ e _hard_ skills exigidos ao longo da carreira vão diferir bastante. Neste contexto, um avanço significativo naquele debate sobre o que faz a senioridade de um profissional de dados poderia ser ganho de um mapeamento de todas àquelas diferentes atuações das pessoas, dos tipos de problemas que resolvem, das tecnologias que usam e da realidade das empresas em que trabalham.



# O que os dados falam sobre a senioridade dos Cientistas de Dados?

Parágrafo #4: falar da disponibilidade dos dados, baixá-los e carregá-los.

```{r carrega_dados}
# carregando os pacotes necessários para a exploração dos dados
library(tidyverse) # core
library(reactable) # tabelas interativas
library(ggridges) # ridge plots
library(scales) # escalas dos gráficos
library(vegan) # análise multivariada
library(patchwork) # compor figuras
library(gghighlight) # para o highlight
library(glue) # concatenar strings
library(tidymodels) # machine learning
library(tidytext) # arrumar os textos

# carregando os dados da pesquisa State of Data
df <- read_csv(file = 'data/raw/State of Data 2021 - Dataset - Pgina1.csv')
# df <- read_csv(file = '_posts/2022-12-31-state-of-data-2021/data/raw/State of Data 2021 - Dataset - Pgina1.csv')

# criando um dicionário para mapear o nome das colunas no estado atual para um nome
# mais legível, bem como para conseguirmos mapear o texto dela às figuras depois
dicionario <- tibble(
  ## pegando o nome das colunas do dataframe
  coluna = names(df) 
) %>%
  ## limpando o string com o nome das colunas - o padrão geral é "(Pergunta, texto)",
  ## onde a Pergunta é codificada com base em três informações: Parte, Letra da Pergunta,
  ## Letra da Opção escolhida. Isto é representado através do código: 
  ## 'P<numero_parte>_<letra_da_pergunta>_<letra_opcao>'. A ideia aqui será quebrar cada
  ## nome de coluna em parte, letra da pergunta, letra da opção e texto da pergunta, bem 
  ## como mapear se aquela é uma pergunta principal (e.g., 'P<numero>' ou 'P<numero>_<letra>').
  ## Para tal, vamos começar tratando o texto dos nomes das colunas que capturamos aqui e,
  ## na sequência, vamos separarar a tupla com base num padrão de regex
  mutate(
    ### removendo as aspas simples no nome das colunas: e.g., ('P0', 'id') -> (P0, id)
    informacao = str_replace_all(string = coluna, pattern = "'", replacement = ''),
    ### removendo os parenteses do nome das colunas: e.g., (P0, id) -> P0, id
    informacao = str_replace_all(string = informacao, pattern = '\\(|\\)', replacement = ''),
    ### ajustando a primeira coluna do dataframe, (P0, id) pois é a única delas que foge do
    ### padrão "(Parte , texto)", onde Parte e texto estão separados por espaço-vírgula-espaço
    informacao = str_replace_all(string = informacao, pattern = 'P0, id', replacement = 'P0 , id')
  ) %>% 
  # colocando o identificador da pergunta daquele do texto de descrição da pergunta em colunas
  # diferentes com base no padrão de regex 'espaço-vírgula-espaço' que os separa
  separate(col = 'informacao', into = c('pergunta_id', 'texto'), sep = ' , ') %>% 
  # separando o código identificador da pergunta em parte, letra da pergunta e letra da opcao
  separate(col = 'pergunta_id', into = c('parte', 'pergunta', 'opcao'), sep = '_', remove = FALSE) %>% 
  # corrigindo typos e coisas similares no dicionario com o nome das colunas vindo dos próprios
  # dados ou da manipulação
  mutate(
    ### adicionando uma coluna booleana indicando se cada uma das perguntas é uma pergunta
    ### principal ou uma resposta à uma pergunta principal - a última é definida pelo padrão
    ### de regex abaixo como estamos negando o teste, o TRUE marca as perguntas principais
    pergunta_principal = str_detect(string = coluna, pattern = 'P[2-9]_[a-z]_', negate = TRUE),
    ### as opções da pergunta P3_d acabaram ficando bugadas na tabela original, de forma que
    ### as opções vieram dentro do texto de descrição da pergunta. Assim, precisamos resgatar
    ### a letra das opções de dentro do texto, e colocar ela de volta no identificador dessa
    ### pergunta quando for o caso
    opcao = case_when(pergunta_id == 'P3_d_' ~ str_extract(string = texto, pattern = '^[a-k](?=\\s)'),
                      TRUE ~ opcao),
    pergunta_id = case_when(pergunta_id == 'P3_d_' ~ paste0(pergunta_id, opcao),
                            TRUE ~ pergunta_id),
    ### limpando o texto de descrição da pergunta para remover o typo do leakage da opção e 
    ### whitespace que possa haver no texto
    texto = case_when(pergunta_id == 'P3_d_' ~ str_remove(string = texto, pattern = '^[a-k]\\s'),
                      TRUE ~ texto),
    texto = str_squish(string = texto)
  )

## colocando o dicionário de identificador das perguntas e opções em uma tabela para referência rápida 
dicionario %>% 
  # adicionando o identificador único da parte-pergunta como uma coluna no dataframe, de forma a utilizarmos 
  # essa informação mais à frente para mapear que parte-pergunta é múltipla escolha e a remapear o título
  # original da questão às opções da múltipla escolha. Todas as perguntas de múltipla escolha que vamos
  # considerar estão da Parte 2 em dia, e são marcadas pelo sufixo '_' após a letra da pergunta 
  mutate(
    pergunta_parte_id = case_when(
      str_detect(string = pergunta_id, pattern = 'P[2-9]_[a-z]_') ~ str_extract(string = pergunta_id, pattern = 'P[2-9]_[a-z]'),
      TRUE ~ pergunta_id
    )
  ) %>% 
  # agrupando o dataframe pelo identificador da parte-pergunta
  group_by(pergunta_parte_id) %>% 
  # identificando as parte-perguntas que são múltipla escolhas através da quantidade de vezes que este 
  # identificador aparece - quando existem diversas opções associadas à uma parte-pergunta, ela deve
  # aparecer mais de uma vez; assim, se mapearmos as linhas associadas à partes-pergunta que aparecem
  # mais de uma vez, teremos acesso ao indicador que estamos buscando
  mutate(
    contem_opcao = n() > 1
  ) %>% 
  # retendo todas as observações de  partes-pergunta que não são de múltipla escolha (i.e., '!contem_opcao')
  # ou todas as observações de partes-pergunta que são de múltipla escolha, desde que não seja a primeira 
  # linha da parte-pergunta (i.e., 'contem_opcao & row_number() > 1') - com este último passo estamos 
  # removendo efetivamente a linha que contém o título da pergunta que dá acesso as opções, o que fará
  # com que a tabela a seguir não traga como opção o título da pergunta, somente as opções mesmo
  filter(!contem_opcao | contem_opcao & row_number() > 1) %>% 
  # desagrupando o dataframe
  ungroup %>% 
  # selecionando apenas as colunas que contém as informações que precisaremos para criar a tabela
  select(pergunta_parte_id, opcao, texto_pergunta_opcao = texto) %>%
  # juntando o dicionário para mapear a pergunta_parte_id ao seu texto - isso servirá para pegarmos
  # o titulo de cada pergunta apenas
  left_join(y = select(dicionario, pergunta_id, texto), by = c('pergunta_parte_id' = 'pergunta_id')) %>% 
  # colando o identificador da pergunta_parte com o texto dela - i.e., o texto da pergunta em si
  mutate(texto = paste0('<b>', pergunta_parte_id, '</b><br>', texto)) %>% 
  # dropando a coluna que contém o identificador pergunta_parte_id, pois já temos essa informação
  # mapeada na coluna com o texto da pergunta
  select(-pergunta_parte_id) %>% 
  # criando a tabela de referencia com o reactable
  reactable(
    groupBy = 'texto', 
    columns = list(
      texto                = colDef(name = 'Pergunta', html = TRUE, width = 300, maxWidth = 300),
      opcao                = colDef(name = 'Opções', aggregate = 'unique', width = 100, maxWidth = 100),
      texto_pergunta_opcao = colDef(name = 'Respostas', width = 200, maxWidth = 200)
    ), 
    showPageSizeOptions = TRUE, defaultPageSize = 5, borderless = TRUE, striped = TRUE, 
    highlight = TRUE, compact = TRUE, style = list(fontSize = '14px')
  )
```

Paragráfo #5: falar da necessidade de limpar o nome das colunas e corrigir algumas informações.

```{r corrige_dados_da_pesquisa}
# renomeando as colunas e implementando pequenos tratamentos aos dados
df <- df %>% 
  # substituindo a tupla mais complexa que está atualmente no nome das colunas pelo código
  # identificador de cada uma das perguntas a partir do dicionário de dados que criamos - 
  # i.e., "(Pergunta, texto)" -> Pergunta
  set_names(nm = pull(dicionario, pergunta_id)) %>% 
  # corrigindo erros gerais na base de dados
  mutate(
    # corrigindo grafia de Arquiteto de dados, que aparece das duas formas na base de dados
    P2_f = ifelse(test = P2_f == 'Arquiteto de dados', yes = 'Arquiteto de Dados', no = P2_f),
    # removendo o ponto final da coluna P4_a
    P4_a = str_remove(string = P4_a, pattern = '\\.')
  ) %>% 
  # removendo registros duplicados - existem 4 pessoas cujas respostas aparecem duas vezes
  # na base de dados - 1 Cientista de dados, 1 Dev, 1 Engenheiro de ML e 1 Tech Lead
  distinct(P0, .keep_all = TRUE)
```

Parágrafo #6: descrever a população que temos, e dizer que vou focar em cientistas de dados.

```{r fig_observacoes_por_area, fig.height = 5, fig.width = 7}
# criando figura para descrever a quantidade de respondentes por tipo de atuação
count(df, P4_a) %>% 
  # reordenando as atuações para que a figura fique com a barra em ordem decrescente
  mutate(P4_a = str_wrap(string = P4_a, width = 10),
         P4_a = fct_reorder(.f = P4_a, .x = n, .desc = TRUE)) %>% 
  # criando a figura
  ggplot(mapping = aes(x = P4_a, y = n, fill = P4_a)) +
  geom_col(color = 'black', show.legend = FALSE) +
  geom_text(mapping = aes(label = paste0(round(x = (n / sum(n))  * 100, digits = 2), '%')), 
            stat = 'identity', vjust = -1) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 950), 
                     breaks = seq(from = 0, to = 1000, by = 100)) +
  scale_fill_manual(values = c('grey15', 'grey30', 'grey45', 'grey65', 'grey80', 'grey95')) +
  labs(
    title = 'Qual a atuação no dia a dia dos respondentes do State of Data 2021?',
    x     = 'Atuação no dia a dia',
    y     = 'Quantidade de respondentes'
  )
```

Parágrafo #7: Como está distribuida a senioridade dos cientistas de dados que responderam à pesquisa?

```{r fig_observacoes_por_senioridade, fig.height = 5, fig.width = 7}
# criando um dataframe que contem a matriz de atuação de cada pessoa respondente que diz 
# atuar como Cientista de Dados e o nivel de senioridade associada à cada uma delas
df_atuacao <- df %>%
  # pegando apenas as observações das pessoas que responderam ter uma atuação que reflete 
  # a de uma pessoa cientista de dados
  filter(P4_a == 'Ciência de Dados') %>% 
  # pegando a coluna com o identificador do respondente e o seu nível de senioridade, bem
  # como todas as colunas que contém as respostas sobre as atuações gerais e específicas 
  # dos respondentes cuja atuação no dia a dia foi o de Ciência de Dados
  select(P0, P2_g, matches('P4_[cdfgh]_'), matches('P8_[abcd]_')) %>% 
  # dropando observações que possuem valores faltantes - isso ocorre devido ao mascaramento
  # de dados
  drop_na()

# plotando a quantidade de respondentes por nivel de senioridade
ggplot(data = df_atuacao, mapping = aes(x = P2_g, fill = P2_g)) +
  geom_bar(color = 'black', show.legend = FALSE) +
  geom_text(mapping = aes(label = paste0(round(x = (..count.. / sum(..count..))  * 100, digits = 2), '%')), 
            stat = 'count', vjust = -1) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 180), breaks = seq(from = 0, to = 180, by = 40)) +
  scale_fill_manual(values = cores_data_hackers) +
  labs(
    title    = 'Qual o nível de senioridade das pessoas Cientista de Dados?',
    subtitle = '40% dos respondentes têm o nível de senioridade Pleno, enquanto os outros 60% são divididos\npraticamente de forma igual entre os níveis Júnior e Sênior',
    x        = 'Nível de senioridade',
    y        = 'Número de respondentes'
  )
```

Parágrafo #8: Atuações por respondente.

```{r fig_respondentes_atuacoes, fig.height = 5, fig.width = 7}
# fazendo um shuffle na base antes de separar os dados de treino e de teste, para tentar quebrar 
# qualquer tipo de estrutura que possa haver na base de dados
set.seed(42)
df_atuacao <- slice_sample(.data = df_atuacao, prop = 1, replace = FALSE)

# fazendo o split da base analitica
set.seed(33)
df_atuacao <- initial_split(data = df_atuacao, prop = 0.8, strata = P2_g) %>% 
  training()

# criando a figura para mostrar a distribuição da quantidade de atuações distintas dos 
# respondentes por nivel de senioridade
select(df_atuacao, -c(P0, P2_g)) %>% 
  # como os respondentes estão na linhas e as perguntas nas colunas, o somatório das 
  # linhas nos trará a  quantidade total de atuações distintas que cada um dos 
  # respondentes assinalou
  rowSums %>% 
  # colocando o resultado da operação em um tibble, para facilitar a tarefa de plotagem
  enframe(value = 'n_atuacoes') %>% 
  # adicionando o indicador de senioridade - como os resultados estao na mesma ordem dos
  # respondentes,  basta copiar a informação do dataframe original para cá
  mutate(P2_g = df_atuacao$P2_g) %>% 
  # criando a figura per se
  ggplot(mapping = aes(x = n_atuacoes, y = P2_g, fill = P2_g)) +
  geom_density_ridges2(quantile_lines = TRUE, quantiles = 2, vline_color = 'grey90', 
                       scale = 0.9, show.legend = FALSE) +
  scale_fill_manual(values = cores_data_hackers) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_x_continuous(breaks = seq(from = 0, to = 100, by = 10)) +
  labs(
    title    = 'Quantas atuações os respondentes têm por nível de senioridade?',
    subtitle = 'Parece existir uma diferença na quantidade de atuações assinaladas de acordo com a senioridade do respondente',
    x        = 'Quantidade de atuações do respondente',
    y        = 'Senioridade do respondente'
  )
```

Parágrafo #9: frequência de atuações.

```{r fig_frequencia_atuacoes, fig.height = 6, fig.width = 7}
# criando a figura para mostrar a distribuição da frequência com a qual as atuações apareceram
# entre os respondentes
select(df_atuacao, -c(P0, P2_g)) %>% 
  # como os respondentes estão na linhas e as perguntas nas colunas, o somatório das colunas 
  # nos trará a  quantidade de respondentes que disseram ter aquele tipo de atuação
  colSums %>%
  # colocando o vetor resultante em ordem decrescente, de forma a conseguimos rankeá-lo mais
  # racilmente depois
  sort(decreasing = TRUE) %>% 
  # passando o vetor para um tibble, onde teremos uma coluna com o identificador da pergunta 
  # e a outra coluna com a quantidade de pessoas respondentes que disseram ter aquele tipo de
  # atuação
  enframe(name = 'pergunta_id', value = 'n_respondentes') %>% 
  # removendo todas as atuações que não tiveram nenhum respondente
  filter(n_respondentes > 0) %>% 
  # mapeando o identificador único de cada pergunta ao seu respectivo texto, de forma a usar 
  # essa  informação mais tarde na figura
  left_join(y = dicionario, by = 'pergunta_id') %>%
  # enriquecendo a base de com informações para plotarmos
  mutate(
    # calculando a proporção total dos respondentes que disseram ter cada uma das atuações
    proporcao    = n_respondentes / nrow(df_atuacao),
    sequencia    = 1:n(),
    to_highlight = sequencia %in% c(1, 2, 3, 21, 27, 63, 124, 125),
    texto = str_trunc(string = texto, width = 47),
    texto = str_wrap(texto, width = 30)
  ) %>% 
  ggplot(mapping = aes(x = sequencia, y = proporcao)) +
  geom_point(size = 3, shape = 21, color = 'black', fill = 'grey50') +
  gghighlight(
    to_highlight, 
    label_key = texto, 
    label_params = list(force_pull = -0.039, label.size = NA, fill = NA, seed = 666, vjust = 0.6,
                        min.segment.length = 0.3),
    unhighlighted_params = list(shape = 16, size = 1, color = 'black')
  ) +
  scale_x_continuous(breaks = c(1, seq(from = 20, to = 150, by = 20))) +
  scale_y_continuous(labels = label_percent(),
                     breaks = seq(from = 0, to = 1, by = 0.1), limits = c(0, 1)) +
  labs(
    title    = 'Quais as atuações mais frequentes entre os respondentes?',
    subtitle = 'A maior parte das atuações é pouco frequente entre os respondentes da pesquisa',
    x        = 'Rank de frequência',
    y        = 'Porcentagem de pessoas respondentes'
  )
```

Parágrafo #10: Como variou a distribuição de atuações por respondente?

```{r fig_matriz_atuacao, fig.height = 6, fig.width = 7}
# criando uma matriz para visualizar a variação na marcação
df_atuacao %>% 
  # passando as informações sobre a atuação do formato largo para o formato longo - i.e., cada
  # uma das atuações para cada pessoa respondente passa a estar nas linhas ao invés de nas colunas
  pivot_longer(cols = -c(P0, P2_g), names_to = 'atuacao', values_to = 'flag') %>% 
  # agrupando o dataframe pelo nivel de atuacao da pessoa respondente
  group_by(atuacao) %>% 
  # somando a quantidade total de pessoas respondentes que disseram ter cada uma das atuações
  # isso acabará replicando esse total para cada uma das atuações, mas o intuito é esse mesmo
  # pois usaremos essa informação mais abaixo para ordenar as atuações daquela com maior número
  # de respondentes para a com o menor número
  mutate(
    total_atuacao = sum(flag)
  ) %>% 
  # regrupando o dataframe pelo identificador de cada pessoa respondente
  group_by(P0) %>% 
  # somando a quantidade total de atuação que cada pessoa respondente disser ter. Isso também
  # acabará replicando esse total entre todas as linhas de um dado respondente mas, novamente, 
  #  usaremos essa informação mais abaixo para ordenar as pessoas respondentes daquelas com o
  # maior número de atuações para a com o menor número
  mutate(
    total_respondente = sum(flag)
  ) %>% 
  # quebrando a estrutura de grupos do dataframe
  ungroup %>% 
  # preparando os dados para criar a matriz de respondentes por atuação
  mutate(
    # definindo a ordem dos respondentes de acordo com a quantidade total de atuações que cada
    # uma dessas pessoas marcou
    P0       = fct_reorder(.f = P0, .x = total_respondente),
    # definindo a ordem das atuações de acordo com a quantidade total de pessoas respondentes
    # que disseram ter aquele tipo de atuação
    atuacao  = fct_reorder(.f = atuacao, .x = total_atuacao, .desc = TRUE),
    # codificando uma coluna para carregar o mapa de cores do preenchimento da matriz de acordo
    # com o nível de senioridade da pessoa respondente
    fill_col = ifelse(test = flag == 1, yes = P2_g, no = 'Vazio')
  ) %>% 
  # criando a figura per se
  ggplot(mapping = aes(x = atuacao, y = P0, fill = fill_col)) +
  geom_tile(show.legend = FALSE) +
  scale_fill_manual(values = c(cores_data_hackers, 'white')) +
  labs(
    title    = 'De que forma a atuação variou entre os respondentes?',
    subtitle = 'As atuações não parecem estar tão bem alinhadas à senioridade do respondente',
    caption  = 'As linhas da matriz estão ordenadas de cima para baixo, do respondente com maior número de atuações para aquele\nde menor. De forma similar, a ordenação da matriz da esquerda para a direita representa àquelas atuações que foram\nselecionadas por quase todos os respondentes para àquelas que foram pouquíssimo selecionadas. As cores representam\nos respondentes nos três níveis de atuação, seguindo a mesma paleta utilizada anteriormente.',
    x        = 'Atuação',
    y        = 'Pessoa respondente'
  ) +
  theme(
    axis.text = element_blank(),
    axis.line = element_blank()
  )
```

Parágrafo #11: Quão diferentes são os cientistas de dados?

```{r fig_betadisper, fig.width = 7, fig.height = 7}
# calculando a dissimilaridade de atuação entre todos os respondentes da pesquisa, utilizando
# a dissimilaridade de Jaccard
matriz_distancia <- vegdist(x = select(df_atuacao, -c(P0, P2_g)), method = 'jaccard')

# implementando uma análise de dispersão do modo de atuação de acordo com a senioridade da
# pessoa respondente
set.seed(33)
analise_dispersao <- betadisper(d = matriz_distancia, group = df_atuacao$P2_g, type = 'centroid')

# criando uma figura para visualizar a dispersão da forma de atuação dos respondentes de
# acordo com o seu grau de senioridade
## extraindo os escores da posição dos respondentes na ordenação da PCoA
escores_respondentes <- scores(x = analise_dispersao, display = 'sites') %>% 
  # parseando a matriz de escores para um dataframe, uma vez que a classe de objeto 
  # resultante não interage bem com o tidyverse
  data.frame %>% 
  # colocando a senioridade do respondente como uma coluna no dataframe - usaremos essa
  # informação para mapear as cores dos pontos à senioridade do respondente; além disso,
  # como o input e o output da função estão alinhados, basta pegar a coluna de senioridade
  # do input e copiar ela para dentro deste output
  mutate(P2_g = df_atuacao$P2_g)

# levantando os dados necessários para desenhar o convex hull ao redor de cada nivel de
# senioridade no gráfico de dispersão
poligonos_senioridade <- escores_respondentes %>% 
  # agrupando o dataframe pelo nivel de senioridade, de forma a obtermos o convex hull para
  # cada nivel de senioridade
  group_by(P2_g) %>% 
  # pegando as instância que podem ser usadas para desenhar o convex hull do nível de senioridade
  slice(chull(PCoA1, PCoA2))

# extraindo as coordenadas da posição dos centroides relacionados à cada um dos níveis
# de senioridade
posicao_centroides <- scores(x = analise_dispersao, display = 'centroids') %>% 
  # parseando a matriz de escores para um dataframe, uma vez que a classe de objeto 
  # resultante não interage bem com o tidyverse
  data.frame %>% 
  # adicionando o string com a senioridade ao dataframe - essa informação está como
  # rowname do dataframe
  rownames_to_column(var = 'P2_g')

# criando a figura per se
ggplot(data = escores_respondentes, mapping = aes(x = PCoA1, y = PCoA2, shape = P2_g, fill = P2_g)) +
  geom_hline(yintercept = 0, color = 'grey80') +
  geom_vline(xintercept = 0, color = 'grey80') +
  geom_polygon(data = poligonos_senioridade, alpha = 0.05, color = NA) +
  geom_point(size = 2, alpha = 0.3, color = 'white') +
  # adicionando o centroide da distribuição da dispersão dos respondentes na figura, que
  # ficará marcando com uma estrela
  geom_point(
    data = posicao_centroides,
    mapping = aes(x = PCoA1, y = PCoA2, fill = P2_g, shape = P2_g), size = 5, color = 'black'
  ) +
  # adicionando o texto associando o centróide de cada grupo de respondentes à sua senioridade
  geom_text(
    data = posicao_centroides,
    mapping = aes(x = PCoA1, y = PCoA2, label = P2_g, color = P2_g), size = 4, hjust = 1.4, fontface = 'bold'
  ) +
  scale_shape_manual(values = c(21, 22, 24)) +
  scale_color_manual(values = cores_data_hackers) +
  scale_fill_manual(values = cores_data_hackers) +
  labs(
    title    = 'Quão diferente é a atuação dos Cientistas de Dados?',
    subtitle = 'A atuação dos respondentes é bastante heterogênea dentro e entre os níveis de senioridade',
    caption  = '',
    x        = 'PCoA #1',
    y        = 'PCoA #2'
  ) +
  theme(
    legend.position = 'none',
    axis.line = element_blank()
  )
```

# Que fatores estão associados à senioridade do Cientista de Dados?

Explicar racionalização da base e feature engineering.

```{r feature_engineering}
# criando a base analítica a partir da base de dados original da pesquisa, seguindo 
# a lógica de feature engineering explicada no texto
df_base_analitica <- df %>% 
  # pegando apenas as observações das pessoas que responderam ter uma atuação que 
  # reflete a de uma pessoa cientista de dados
  filter(P4_a == 'Ciência de Dados') %>% 
  # codificando features a partir dos dados disponíveis na base de dados original
  mutate(
    # adicionando um indicador para mapear se a pessoa respondente possui o título 
    # de cientista de dados no cargo ou não
    has_role = case_when(
      str_detect(string = P2_f, pattern = 'Cientista de Dados') ~ 1L,
      TRUE ~ 0L
    ),
    # agrupando o setor de atuação dos respondentes em torno de três categorias 
    # mais simples - Indústria, Comércio e Serviços (i.e., só Serviços) e Indeterminada
    tipo_industria = case_when(
      str_detect(string = P2_b, pattern = 'Agronegócios|Construção|Energia|Indústria|Alimentício|Automotivo') ~ 'Indústria',
      is.na(P2_b) | P2_b == 'Outro' ~ 'Indeterminado',
      TRUE ~ 'Serviços'
    ),
    # mapeando o tamanho da empresa da pessoa respondente às categorias definidas pelo
    # IBGE de acordo com o número de colaboradores - simplificando e utilizando a categoria
    # 'Comércio e Serviços', dado que a maior parte dos respondentes de Ciência de Dados
    # está nessa área
    tamanho_empresa = case_when(
      is.na(P2_c) ~ 'Desconhecido',
      P2_c %in% c('de 1 a 5', 'de 6 a 10') ~ 'Microempresa',
      P2_c %in% c('de 11 a 50') ~ 'Pequeno porte',
      P2_c %in% c('de 51 a 100') ~ 'Médio porte',
      TRUE ~ 'Grande porte'
    ),
    # juntando tudo o que é grau de formação onde a pessoa ainda não tem um diploma de 
    # ensino superior (ou preferiu) não informar em uma categoria só
    instrucao = case_when(
      P1_h %in% c('Estudante de Graduação', 'Não tenho graduação formal', 'Prefiro não informar') ~ 'Sem diploma',
      TRUE ~ P1_h
    )
  ) %>% 
  # pegando apenas as colunas que têm as informações que utilizaremos para a modelagem
  select(P0, P2_g, has_role, tamanho_empresa, instrucao, tipo_industria, 
         matches('P4_[cdfgh]_'), matches('P8_[abcd]_')) %>% 
  # passando todas as colunas que estão como double para integer
  mutate(across(where(is.double), as.integer)) %>% 
  # dropando qualquer linha com NA
  drop_na() %>% 
  # agrupando o tibble linha a linha
  rowwise() %>%
  # calculando a quantidade de respostas gerais e especificas de cada pessoa respondente
  mutate(
    respostas_geral = sum(c_across(contains('P4'))),
    respostas_especificas = sum(c_across(contains('P8')))
  ) %>%
  # quebrando o agrupamento das linhas
  ungroup
```

Criando o modelo no tidymodels.

```{r modelo_tidymodels}
# fazendo o split da base analitica usando a mesma divisão da base em treino e teste do que aquela
# utilizada na análise exploratória de dados - para isso, usaremos o make_splits, que levará como
# argumentos os índices das instâncias que estavam na base de treino utilizada na EDA para criar 
# o split de dados baseados nas mesmas instâncias, garantindo que não há leakage da EDA para a 
# modelagem
split_dos_dados <- make_splits(
  x = list(
    analysis = which(df_base_analitica$P0 %in% df_atuacao$P0), 
    assessment = which(!df_base_analitica$P0 %in% df_atuacao$P0)
  ),
  data = df_base_analitica
)

# criando folds para validacao cruzada
set.seed(42)
skfolds <- vfold_cv(data = training(split_dos_dados), v = 5, strata = P2_g)

# criando a receita de preprocessamento dos dados
## criando uma receita através da qual vamos modelar a senioridade da pessoa respondente com base em
## todas as informações disponíveis na base analítica - usando o split de treino para criar a receita
## de pre-processamento (e que só será treinada de fato quando rodarmos cada um dos modelos)
pre_processamento <- recipe(P2_g ~ ., data = training(split_dos_dados)) %>% 
  # parseando a coluna P0 como o identificador único de cada pessoa respondente
  update_role(P0, new_role = 'id') %>% 
  # fazendo o one hot encoding das variáveis categóricas com mais de um nível 
  step_dummy(tamanho_empresa, instrucao, tipo_industria, one_hot = TRUE) %>% 
  # adicionando uma interação entre o tamanho da empresa e o tipo de industria, de forma a testar a 
  # hipotese que o nivel de senioridade exigido difere de acordo com o tipo de ramo no qual a empresa
  # da pessoa respondente atua
  step_interact(
    terms = ~ starts_with('tamanho_empresa'):starts_with('tipo_industria') +
      starts_with('tamanho_empresa'):has_role +
      starts_with('tipo_industria'):has_role
  ) %>%
  # removendo todas as variáveis preditoras que têm a variância muito baixa - i.e., são todas variáveis
  # categóricas com um viés grande demais para uma das respostas (e.g. ou quase tudo 1 ou quase tudo 0)
  step_nzv(all_predictors(), freq_cut = 98/2) %>% 
  # normalizando todas as variáveis preditoras que, embora sejam categóricas, faz com que possamos 
  # comparar o impacto de cada uma delas considerando a frequência com a qual ocorrem
  step_normalize(respostas_geral, respostas_especificas)

# criando uma instância do modelo de regressão multinomial usando a engine do glmnet e deixando os dois
# hiperparametros principais para a otimização bayesiana - equivalente ao C e ao l1_ratio do sklearn
regressao_multinomial <- multinom_reg(penalty = tune(), mixture = tune()) %>% 
  set_engine(engine = 'glmnet', standardize = FALSE) %>% 
  set_mode(mode = 'classification')

# criando workflow para a regressão multinomial - seria a mesma coisa que criar uma instância do pipeline
# do sklearn, empacotando o pre-processamento e o algoritmo em um objeto só
pipeline <- workflow() %>% 
  add_recipe(recipe = pre_processamento) %>% 
  add_model(spec = regressao_multinomial)

# implementando uma otimização bayesiana de hiperparâmetros para a regressão multinomial - usando o log
# loss como métrica principal e monitorando o AUC. Este processo será paralelizado para ganharmos um 
# pouco mais de velocidade
doParallel::registerDoParallel()
set.seed(42)
grid_search <- pipeline %>% 
  tune_bayes(
    resamples = skfolds, iter = 50, metrics = metric_set(mn_log_loss, roc_auc), initial = 15,
    control = control_bayes(no_improve = 10, seed = 42, verbose = TRUE, parallel_over = 'resamples')
  )

# extraindo a melhor combinação de hiperparâmetros do estimador a partir do grid search e finalizando o 
# pipeline com esta combinação 
melhor_estimador <- pipeline %>% 
  finalize_workflow(parameters = select_best(x = grid_search, metric = 'mn_log_loss'))

# treinando o melhor estimador na base de treino e escorando ele na base de teste
modelo_treinado <- melhor_estimador %>% 
  last_fit(split = split_dos_dados, metrics = metric_set(mn_log_loss, roc_auc, recall, precision))

# extraindo o valor das métricas de avaliação do modelo definidas acima
metricas_no_teste <- modelo_treinado %>% 
  collect_metrics() %>% 
  # pegando apenas a coluna com o nome da metrica e o seu valor
  select(.metric, .estimate) %>% 
  # colocando cada uma das metricas como uma coluna em um tibble
  pivot_wider(names_from = .metric, values_from = .estimate)
# printando as metricas do modelo na base de teste em uma tabela
rmarkdown::paged_table(x = metricas_no_teste)
```

Matriz de confusão.

```{r fig_matriz_confusao, fig.height = 4, fig.width = 7}
# extraindo a matriz de confusão do modelo treinado e plotando a figura
modelo_treinado %>% 
  # extraindo o pipeline com o modelo ja treinado
  extract_workflow() %>% 
  # adicionando as previsões à base de teste
  augment(new_data = testing(split_dos_dados)) %>% 
  # extraindo a matriz de confusao a partir da base de teste
  conf_mat(truth = P2_g, estimate = .pred_class) %>% 
  # extraindo a tabela que compõem a matriz de confusão a partir do objeto resultante
  # de forma a utilizar essa informação para personalizar a plotagem da nossa matriz de confusão
  pluck('table') %>%
  # parseando o tipo de dado resultante para um dataframe
  data.frame %>% 
  # adicionando informacoes para ajudar na criação da figura
  mutate(
    # adicionando indicadores para determinar se a previsão estava certo, se a previsão é de
    # que a pessoa atua em um nível abaixo do qual ela está ou se ela está atuando em um nível
    # acima do qual ela está
    tipo_previsao = case_when(
      Truth != Prediction ~ 'errou',
      TRUE ~ 'acertou'
    ),
    # reordenando os niveis da coluna com as class labels da previsao de forma a ter um output
    # mais similar à matriz de confusao do sklearn
    Prediction = fct_rev(f = Prediction)
  ) %>% 
  # criando a figura per
  ggplot(mapping = aes(x = Truth, y = Prediction, fill = tipo_previsao, label = Freq)) +
  geom_tile(mapping = aes(alpha = Freq), color = 'black', show.legend = FALSE) +
  geom_text(fontface = 'bold') +
  scale_fill_manual(values = c('deepskyblue1', 'tomato1')) +
  labs(
    title    = 'Como o modelo performou na base de teste?',
    x        = 'Senioridade observada',
    y        = 'Senioridade predita',
    caption  = 'A diagonal principal (em azul) apresenta as classificações corretas feitas pelo modelo na base de teste, enquanto\nque os demais valores (em vermelho) representam os erros do modelo. A transparência das cores remete à\nquantidade de pessoas respondentes mapeadas à cada combinação de categorias preditas e observadas.'
  ) +
  theme(
    axis.line = element_blank()
  )
```

Coeficientes.

```{r fig_coeficientes_modelo, layout = 'l-screen', preview =  TRUE, fig.width = 25, fig.height = 8}
# criando uma figura para analisar a variação na contribuição de cada feature para a previsão
# de cada nível de senioridade
df_coeficientes <- modelo_treinado %>% 
  # extraindo o pipeline com o modelo ja treinado
  extract_workflow() %>% 
  # extraindo os coeficientes do modelo treinado já dentro de um tibble
  tidy %>% 
  # dropando o intercepto e qualquer feature cuja estimativa do slope tenha sido 0
  filter(term != '(Intercept)', estimate != 0) %>% 
  # juntando o dicionario de id das perguntas para o texto das perguntas, de forma a
  # nos ajudar a dicionar um texto mais informativo as features com maior impacto
  # sobre cada nível de senioridade
  left_join(y = dicionario, by = c('term' = 'pergunta_id')) %>% 
  # agrupando o tibble pelo nivel de senioridade para fazermos a operação seguinte
  group_by(class) %>% 
  # extraindo as 10 features com maior impacto sobre a previsão de cada nivel de senioridade,
  # removendo features sem contribuição desta lista
  filter(estimate != 0) %>% 
  slice_max(order_by = abs(estimate), n = 10) %>% 
  # dropando o agrupando pelo nível de senioridade
  ungroup %>% 
  # editando os textos de cada pergunta para torná-los mais apresentável na figura, além de
  # ajustar a ordem das features dentro de cada nível de senioridade de forma a tornar mais
  # clara a variação na contribuição de cada feature por nível
  mutate(
    # padronizando os textos de descrição criando uma nova coluna - colocando o nome da feature
    # de acordo com aquele existente no dicionário quando ele existir ou o nome do termo quando
    # a feature não existir naquele dicionario - e.g., as variáveis com os níveis de instrução,
    # tipo e tamanho de empresa
    termo = ifelse(test = is.na(texto), yes = term, no = texto),
    # removendo todas as ocorrências de pontos nas strings dos termos, que neste caso estão sendo
    # usados para representar o espaço entre palavras
    termo = str_replace_all(string = termo, pattern = '\\.', replacement = ' '),
    # tratando qualquer string relacionada às features de tamanho da empresa e tipo de indústria,
    # de forma que o nível da categoria esteja mais claramente relacionada à feature em si (e.g.,
    # 'Empresa de Grande Porte', ao invés da visualização trazer apenas 'Grande Porte')
    termo = str_replace(string = termo, pattern = 'tamanho_empresa_', replacement = 'Empresa de '),
    termo = str_replace(string = termo, pattern = 'tipo_industria_', replacement = 'Indústria de '),
    # substituindo todos os prefixos relacionados à feature de instrução pelo verbo 'Ter', de forma
    # a tornar mais intuitivo o que o essa feature quer dizer
    termo = str_replace(string = termo, pattern = 'instrucao_', replacement = 'Ter '),
    # adicionando o separador corretor para as ocorrências de pós-graduação e entre as opções de ter
    # bacharelado ou graduação
    termo = str_replace(string = termo, pattern = '(?<=Graduação)\\s', replacement = '/'),
    termo = str_replace(string = termo, pattern = '(?<=Pós)\\s', replacement = '-'),
    # tornando mais claro o significado das features relacionadas à quantidade de atuações gerais
    # e específicas assinaladas por cada pessoa respondente
    termo = str_replace_all(string = termo, 
                            pattern = 'respostas_geral', replacement = 'Quantidade de atuações gerais'),
    termo = str_replace_all(string = termo, 
                            pattern = 'respostas_especificas', replacement = 'Quantidade de atuações específicas'),
    # tratando exceção ao nível da feature de instrução onde o caso é não ter diploma de ensino superior
    termo = str_replace_all(string = termo, 
                            pattern = 'Ter Sem diploma', replacement = 'Não ter diploma de ensino superior'),
    # tornando mais clara o significado do string relacionado às interações entre ter o cargo de
    # cientista de dados e as outras features
    termo = str_replace_all(string = termo, 
                            pattern = '(.+)_x_has_role', replacement = 'Ter o cargo de DS em \\1'),
    termo = str_replace(string = termo, pattern = 'has_role', replacement = 'Ter o cargo de DS'),
    # removendo qualquer whitespace do início e/ou do fim de cada string
    termo = str_squish(string = termo),
    # adicionando quebras de linhas à cada strig para tornar mais fácil a visualização dos resultados
    texto_final = str_wrap(string = termo, width = 55),
    # ordenando os termos dentro de cada nível de senioridade de acordo com o valor dos betas,
    # assim poderemos ter uma visão das features com impacto mais positivo para o mais negativo
    # dentro de cada um dos níveis de senioridade
    texto_final = reorder_within(x = texto_final, within = class, by = estimate)
  )

# criando a figura per se
ggplot(data = df_coeficientes, mapping = aes(x = estimate, y = texto_final, fill = class)) +
  facet_wrap(~ class, scales = 'free') +
  geom_vline(xintercept = 0) +
  geom_col(color = 'black', show.legend = FALSE) +
  scale_y_reordered() +
  scale_fill_manual(values = cores_data_hackers) +
  labs(
    title    = 'Quais os fatores mais contribuem para a previsão do nível de senioridade?',
    subtitle = 'Estas são os 10 fatores que têm maior impacto sobre a previsão do nível de senioridade entre os respondentes da pesquisa State of Data 2021',
    x        = 'Contribuição da feature (coeficientes da regressão)'
  ) +
  theme(axis.title.y = element_blank())
```

# O que pode estar errado para o seu nível de atuação?

```{r analise_de_vizinhanca, layout = 'l-body-outset'}
# extraindo o identificador de cada pessoa respondente na base de treino no qual o modelo
# conseguiu prever corretamente o seu nivel de senioridade
ids_acertos_treino <- modelo_treinado %>% 
  # extraindo o pipeline com o modelo ja treinado
  extract_workflow() %>% 
  # adicionando as previsões do modelo à base de treino
  augment(new_data = training(split_dos_dados)) %>% 
  # filtrando apenas as pessoas respondentes onde o modelo acertou o nível de senioridade
  filter(P2_g == .pred_class) %>% 
  # extraindo o identificador único da pessoa respondente
  pull(P0)

# extraindo o identificador de cada pessoa respondente na base de teste no qual o modelo
# errous a previsçao do nivel de senioridade
ids_erros_teste <- modelo_treinado %>% 
  # extraindo o pipeline com o modelo ja treinado
  extract_workflow() %>% 
  # adicionando as previsões do modelo à base de teste
  augment(new_data = testing(split_dos_dados)) %>% 
  # filtrando apenas as pessoas respondentes onde o modelo errou o nível de senioridade
  filter(P2_g != .pred_class) %>% 
  # extraindo o identificador único da pessoa respondente
  pull(P0)

# extraindo os dados que utilizaremos para implementar o algoritmo de vizinhos mais proximos
# esta base deve conter a informação das features já pré-processadas para as pessoas respondentes
# em que o modelo acertou a previsão do nível de senioridade na base de treino e para àquelas
# em que o modelo errou a previsão
df_comparacao <- modelo_treinado %>% 
  # extraindo as etapas de pre-processamento já treinados a partir do pipeline do modelo
  extract_recipe() %>% 
  # aplicando o pre-processamento à toda a base analítica
  bake(new_data = df_base_analitica) %>% 
  # corrigindo os valores da coluna de identificador único de cada pessoa, que vira NA para
  # as instâncias na base de teste - como as duas bases estão alinhadas, basta sobre-escrever
  # a coluna (isto ocorre pois o id é convertido é um fator, e como os identificadores na 
  # base de teste não estão contempladas como níveis conhecidos do fator, eles são convertidos
  # em NA)
  mutate(P0 = df_base_analitica$P0) %>% 
  # pegando apenas as pessoas respondentes que estejam na base de treino e tenham tido seu nível
  # de senioridade previsto corretamente pelo modelo ou àquelas pessoas que estavam na base de
  # teste e tiveram seu nível de senioridade previsto de forma errada pelo modelo
  filter(P0 %in% c(ids_acertos_treino, ids_erros_teste)) %>% 
  # parseando o tibble para um data.frame, de forma a podermos dar nomes à cada uma de suas linhas
  data.frame %>% 
  # colocando o identificador único de cada pessoa como o nome das linhas do data.frame - 
  # isso facilitará a indexação na função de vizinhos mais próximos que aplicaremos
  `row.names<-`(value = .$P0)


# criando funcao para calcular os vizinhos mais próximos de uma pessoa respondente da 
# base de teste que tenha sido classificada de forma errada com base nas pessoas da 
# base de treino que tenham sido classificadas corretamente
pessoa_mais_proxima <- function(pessoa) {
  # pegando a informação da classe à qual a pessoa respondente no input está associada
  classe_observada <- as.character(df_comparacao[pessoa, 'P2_g'])
  
  # pegando todas as instâncias da base de treino que foram classificadas corretamente
  # e que também estão associadas à classe da pessoa respondente que serviu de input
  # para a função - dropando o identificador e a classe das outras pessoas respondentes 
  # uma vez que essa informação é irrelevante para calcular a similaridade entre elas
  instancias_na_classe <- df_comparacao %>%
    filter(P0 %in% ids_acertos_treino, P2_g == classe_observada) %>%
    select(-P0, -P2_g)
  
  # replicando a instância relacionada à pessoa respondente no input dessa função tantas
  # vezes quantas forem as pessoas classificadas corretamente na base de treino. Esta 
  # estrutura de dados resultará em um data.frame com a linha da instância da pessoa do
  # input da função replicada tantas vezes quanto houverem linhas em instancias_na_classe
  instancia_errada <- df_comparacao[rep(x = pessoa, times = nrow(instancias_na_classe)),] %>%
    select(-P0, -P2_g)
  
  # calculando a similaridade do coseno entre todas as pessoas classificadas na classe
  # correta na base de treino e a pessoa classificada na classe errada na base de teste
  # o resultado desta operação é um vetor nomeado, onde os nomes são os identificadores
  # das outras pessoas naquela classe da pessoa input e que foram classificadas corretamente
  # na base de treino, e os valores são a similaridade do coseno entre cada uma delas e
  # as features da pessoa utilizada no input
  similaridade_coseno <- rowSums(instancias_na_classe * instancia_errada) / 
    (sqrt(rowSums(instancias_na_classe ^ 2)) * sqrt(sum(instancia_errada[pessoa, ] ^ 2)))
  
  # passando o vetor nomeado para um tibble, onde uma coluna é o identificador de cada
  # pessoa respondente classificada corretamente naquela classe na base de treino e a
  # outra coluna é a similaridade entre ela e a pessoa respondente utilizada no input
  enframe(x = similaridade_coseno, name = 'P0_acerto', value = 'similaridade') %>% 
    # retendo aquela pessoa que teve maior similaridade com a pessoa utilizada no input
    slice_max(n = 1, order_by = similaridade) %>% 
    # adicionando uma coluna para codificar o identificador da pessoa respondente
    # utilizada como input da função - i.e., àquela classificada na classe errada
    mutate(P0_errado = pessoa) %>% 
    # reorganizando as colunas do tibble antes de retornar os resultados
    relocate(P0_errado, .before = P0_acerto)
}

# aplicando a função aos dados, de forma a identificar quem é a pessoa classificada 
# corretamente na base de treino que é mais similar àquela classificada de forma errada
# na base de teste
df_vizinhos <- map_dfr(.x = ids_erros_teste, .f = pessoa_mais_proxima) 

# criando uma figura para analisar a similaridade entre os vizinhos mais próximos
#ggplot(data = df_vizinhos, mapping = aes(x = similaridade)) +
#  geom_histogram(color = 'black', fill = 'grey50', bins = 9) +
#  scale_y_continuous(breaks = seq(from = 0, to = 15, by = 2), expand = c(0, 0),
#                     limits = c(0, 12)) +
#  scale_x_continuous(breaks = seq(from = 0.3, to = 0.9, by = 0.1)) +
#  labs(
#    title    = 'Quão diferentes são as pessoas respondentes classificadas erradas dos seus pares?',
#    subtitle =  
#    x        = 'Similaridade do coseno',
#    y        = 'Observações'
#  )

# criando uma versão mais longa da base analítica onde mapearemos as respostas de cada pessoa
# respondente às perguntas feitas linha a linha, e utilizaremos estas informações para poder
# identificar mais facilmente as perguntas cujas respostas diferem entre a pessoa que o modelo
# errou a previsão na base de teste e a pessoa mais similar à ela mas que o modelo acertou a
# previsão na base de treino
df_base_analitica_longa <- df_base_analitica %>% 
  # passando todas as colunas de inteiro para caracter, de forma a conseguirmos pivotear a 
  # base para o formato longo - se não fizermos isso, o `pivot_longer` explode uma mensagem
  # de erro pois estaríamos misturando os data types
  mutate(across(where(is.integer), as.character)) %>%
  # passando a base para o formato longo, onde colocaremos as perguntas e as respostas de cada
  # pessoa respondente nas linhas ao invés de nas colunas - isso aumentará muito a quantidade 
  # de linhas na base, mas precisaremos disso para fazer uns joins mais abaixo
  pivot_longer(cols = -c(P0, P2_g), names_to = 'feature', values_to = 'valor') %>% 
  # ajustando o conteúdo de algumas colunas
  mutate(
    # ajustando o significado das features criadas uma vez que elas não constam no dicionario
    feature_tidy = case_when(
      feature == 'has_role' ~ 'Tem o cargo de DS',
      feature == 'tamanho_empresa' ~ 'Tamanho da empresa',
      feature == 'instrucao' ~ 'Nível de instrução',
      feature == 'tipo_industria' ~ 'Tipo de indústria',
      TRUE ~ feature
    ),
    # passando os valores 0 e 1 das dummies para o seu significado real quando for o caso, ou
    # usando o valor da resposta quando relevante
    valor_tidy = case_when(
      valor == '1' ~ 'Sim',
      valor == '0' ~ 'Não',
      TRUE ~ valor
    ),
    # criando uma coluna de resposta, que conterá o nome da feature e o valor da resposta para
    # cada linha - isso nos ajudará depois a mapear que resposta diferiu entre as duas pessoas
    # mais facilmente
    resposta = paste0(feature_tidy, ': ', valor_tidy)
  ) %>% 
  select(-valor)

# levantando os nomes das features que estão entre os top 10 dos maiores coeficientes do elasticnet
# utilizado para modelar a senioridade. Aproveitaremos para remover as features relacionadas à 
# quantidade de respostas marcadas para as atuações gerais e específicas (uma vez que elas obviamente
# vão variar entre as duas pessoas e esta não é uma alavanca acionável muito inteligente), além
# de remover a parte do string que específica a o nível da categoria para as variáveis categóricas
# que contém múltiplos níveis. Esse objeto guardará este resultado como um vetor, onde o texto com
# o nome das features estará escrito de forma similar aquele da coluna `feature` na base analítica
# que criamos no formato longo acima
top_features <- df_coeficientes %>%
  filter(!term %in% c('respostas_geral', 'respostas_especificas')) %>% 
  pull(term) %>% 
  unique %>% 
  str_replace(pattern = '(?<=instrucao|tamanho_empresa|tipo_industria).+', replacement = '') %>%
  unique

# consolidando todos os contra-factuais para cada uma das pessoas respondentes em um data.frame só
df_contra_exemplos <- df_vizinhos %>% 
  # adicionando as features relacionadas às respostas dadas pela pessoa que o modelo errou a previsão
  # na base de teste aos resultados da análise de vizinhança
  left_join(y = df_base_analitica_longa, by = c('P0_errado' = 'P0')) %>% 
  # adicionando as features relacionadas às respostas dadas pela pessoa que o modelo acertou a previsão
  # na base de treino aos resultados da análise de vizinhança
  left_join(y = select(df_base_analitica_longa, -P2_g), 
            by = c('P0_acerto' = 'P0', 'feature'), suffix = c('_errado', '_acerto')) %>% 
  # retendo apenas os registros de cada par de pessoas no qual existe uma diferença entre as 
  # respostas dadas para uma mesma pergunta
  filter(resposta_acerto != resposta_errado) %>% 
  # adicionando a informação do nível de senioridade predito pelo modelo para as pessoas às quais
  # a previsão este errada
  left_join(y = modelo_treinado %>% 
              extract_workflow() %>% 
              augment(new_data = testing(x = split_dos_dados)) %>% 
              select(P0, .pred_class),
            by = c('P0_errado' = 'P0')
  ) %>% 
  # juntando o significado de cada pergunta à base de dados
  left_join(y = select(dicionario, pergunta_id, texto), by = c('feature' = 'pergunta_id')) %>% 
  # adicionando novas informações à base de dados para ajudar na visualização
  mutate(
    # adicionando um indicador para sinalizar se a feature em questão está entre àquelas 10 
    # features mais importantes identificadas pelo elasticnet entre todos os níveis de senioridade
    top_feature = feature %in% top_features,
    # codificando o tipo geral do erro de previsão: ou o modelo previu que pessoa performa acima 
    # do nível no qual ela tem (i.e., 'Júnior que atua como Sênior') ou abaixo dela (i.e., 'Sênior
    # que atua como Júnior')
    direcao_erro = case_when(
      P2_g == 'Júnior' & .pred_class %in% c('Sênior', 'Pleno') ~ 'Para que o Júnior não fosse considerado Sênior',
      P2_g == 'Pleno' & .pred_class == c('Sênior') ~ 'Para que o Júnior não fosse considerado Sênior',
      P2_g == 'Sênior' & .pred_class %in% c('Júnior', 'Pleno') ~ 'Para que o Sênior não fosse considerado Júnior',
      P2_g == 'Pleno' & .pred_class == c('Júnior') ~ 'Para que o Sênior não fosse considerado Júnior',
    ),
    # tratado o texto de descrição da feature - removendo whitespace do início e do fim do string,
    # adicionando o nome tratado da feature quando ele estiver ausente (i.e., para as features que
    # derivamos) e truncando o string de forma que apenas os 50 caracteres de cada um apareça
    texto = str_squish(string = texto),
    texto = ifelse(test = is.na(texto), yes = feature_tidy_acerto, no = texto),
    resumo = str_trunc(string = texto, width = 50)
  ) %>% 
  # removendo as features relacionadas à quantidade de atuações gerais e específicas, uma
  # vez que essa não é uma alavanca acionável de forma inteligente
  filter(!texto %in% c('respostas_geral', 'respostas_especificas'))

# colocando os resultados da análise de vizinhança para cada pessoa na qual o modelo errou a
# previsão na base de teste em uma tabela interativa para a análise
df_contra_exemplos %>%
  select(P0_errado, P2_g, .pred_class, resumo, valor_tidy_errado, valor_tidy_acerto, top_feature) %>%
  mutate(top_feature = ifelse(test = top_feature, yes = 'Sim', no = 'Não')) %>%
  reactable(
    groupBy = 'P0_errado', 
    columns = list(
      P0_errado         = colDef(name = 'Pessoa'),
      P2_g              = colDef(name = 'Senioridade da pessoa', aggregate = 'unique'),
      .pred_class       = colDef(name = 'Senioridade prevista', aggregate = 'unique'),
      resumo            = colDef(name = 'Pergunta'),
      valor_tidy_errado = colDef(name = 'Resposta foi...'),
      valor_tidy_acerto = colDef(name = 'Resposta deveria mudar para...'),
      top_feature       = colDef(name = 'Feature entre top 10?', defaultSortOrder = 'desc')
    ),
    showPageSizeOptions = TRUE, defaultPageSize = 3, borderless = TRUE, striped = TRUE, 
    highlight = TRUE, compact = TRUE, defaultSorted = 'top_feature', 
    style = list(fontSize = '12px')
  )
```

Blablabla.

```{r fig_contra_exemplos, layout = 'l-page', fig.width = 15, fig.height = 8}
# visualizando as mudanças de resposta mais frequentes que deveriam ser feitas para que uma pessoa
# respondente tivesse sido classificada corretamente no seu nível de senioridade
df_contra_exemplos %>% 
  # focando apenas nas respostas que estiverem relacionadas às 10 features mais importantes para a 
  # previsão de acordo com o elasticnet
  filter(top_feature) %>% 
  # contando quantas vezes cada resposta aparece associada à cada pergunta de acordo com o tipo de
  # erro cometido pelo modelo
  count(direcao_erro, resumo, valor_tidy_acerto, name = 'ocorrencias', sort = TRUE) %>% 
  # juntando a quantidade total de pessoas que o modelo errou a classificação de acordo com o tipo
  # de erro cometido, de forma à calcularmos a proporção de vezes que cada uma das mudanças de
  # resposta às perguntas é observada entre as pessoas na base de teste
  left_join(
    y = distinct(df_contra_exemplos, P0_acerto, P0_errado, direcao_erro) %>% 
      count(direcao_erro, name = 'pessoas'), 
    by = 'direcao_erro'
  ) %>%
  mutate(
    proporcao = ocorrencias / pessoas,
    valor_tidy_acerto = case_when(
      valor_tidy_acerto == 'Grande porte' ~ 'Empr. grande porte',
      valor_tidy_acerto == 'Médio porte' ~ 'Empr. médio porte',
      TRUE ~ valor_tidy_acerto
    ),
    valor_tidy_acerto = fct_relevel(.f = valor_tidy_acerto, 'Doutorado ou Phd', 'Mestrado',
                                    'Pós-graduação', 'Graduação/Bacharelado', 'Sem diploma'),
    resumo = str_wrap(string = resumo, width = 30)
  ) %>% 
  # criando a figura per se
  ggplot(mapping = aes(x = proporcao,
                       y = reorder_within(x = resumo, by = proporcao, within = direcao_erro, fun = sum), 
                       fill = valor_tidy_acerto)) +
  facet_wrap(~ direcao_erro, scales = 'free') +
  geom_bar(stat = 'identity', position = 'stack', color = 'black') +
  scale_y_reordered() +
  scale_x_continuous(breaks = seq(from = 0, to = 0.8, by = 0.2), limits = c(0, 0.8),
                     expand = c(0, 0), labels = label_percent()) +
  scale_fill_manual(
    values = c('grey20', 'grey40', 'grey60', 'grey80', 'grey95',
               'darkgoldenrod1', 'lightgoldenrod1', 'tomato2', 'dodgerblue2')
  ) +
  labs(
    title    = 'O que precisaria mudar para corrigir os erros cometidos pelo modelo?',
    subtitle = 'O nível de instrução é o principal fator associado aos erros de classificação feitos pelo modelo - mas a falta ou a existência de alguns conhecimentos de tecnologias e problemas de\nciência de dados também podem colaborar em alguns casos',
    fill     = 'Resposta deveria\nmudar para...',
    x        = 'Proporção das pessoas respondentes na base de teste'
  ) +
  theme(
    axis.title.y = element_blank(),
    legend.title = element_text(face = 'bold')
  )
```

# Conclusões

