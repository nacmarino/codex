---
title: "Quão similares são as notas dos jogos de tabuleiro entre os rankings disponíveis?"
description: |
  Meu principal objetivo neste post é analisar as notas dadas aos jogos de tabuleiros nos rankings do portal da Ludopedia e do portal do BoardGameGeek para determinar quão similares são as notas dadas aos títulos nas mesmas posições entre os dois rankings. Isto é, será que a nota dada ao título na i-ésima posição no ranking da Ludopedia é parecida com a nota dada ao título na mesma posição no ranking do BoardGameGeek?
author:
  - first_name: Nicholas 
    last_name: Marino
    url: https://github.com/nacmarino
date: 10-08-2021
categories:
  - estatistica
  - boardgames
  - infer
output:
  distill::distill_article:
    self_contained: false
    toc: true
    code_folding: true
    highlight: rstudio
draft: true
---

```{r setup, include=FALSE}
# setando as opções gerais dos code chunks
knitr::opts_chunk$set(echo = FALSE, code_folding = FALSE, cache = TRUE, dpi = 200, fig.align = 'center')

# presetando o ggplot2
library(ggplot2)

# setando o tema geral do ggplot2
theme_set(new = theme_minimal(base_family = 'IBM Plex Sans'))

# atualizando o tema
theme_update(
  plot.title    = element_text(face = 'bold', size = 10),
  plot.subtitle = element_text(size = 8),
  plot.caption  = element_text(size = 8),
  axis.title    = element_text(face = 'bold', size = 8),
  axis.text     = element_text(color = 'black', size = 8),
  strip.text    = element_text(face = 'bold', size = 8)
)
```

# Motivação

# Preparação dos dados

```{r}
# carregando os pacotes
library(tidyverse) # core
library(ggside) # para colocar o density plot ao lado
library(ggridges) # para plotar o ridge plot
```

Uma vez que o _scrapping_ da página do ranking da Ludopedia demora um pouquinho, já deixei preparada uma base com estes dados conforme disponíveis no dia 15 de outubro de 2021. Podemos visualizar o conteúdo do ranking naquela data através da tabela abaixo.

```{r df_ludopedia, layout = 'l-page'}
## lendo os dados raspados da ludopedia
ludopedia <- read_rds(file = 'data/ranking_ludopedia.rds')
# ludopedia <- read_rds(file = '_posts/2021-10-24-as-notas-dos-rankings-dos-portais-de-jogos-de-tabuleiro-sao-similares/data/ranking_ludopedia.rds')
rmarkdown::paged_table(x = ludopedia)
```

De forma similar, trago abaixo a tabela com as informações do ranking do BGG, obtidas também no dia 15 de outubro.

```{r df_bgg, layout = 'l-page'}
## lendo os dados raspados da ludopedia
bgg <- read_rds(file = 'data/ranking_bgg.rds')
# bgg <- read_rds(file = '_posts/2021-10-24-as-notas-dos-rankings-dos-portais-de-jogos-de-tabuleiro-sao-similares/data/ranking_bgg.rds')
rmarkdown::paged_table(x = bgg)
```

Como podemos ver, existem muitas similaridades entre os dois conjuntos de dados (_e.g._, título, ano de lançamentos, nota do ranking, quantidade de notas,...). Todavia, as informações que precisamos para endereçar a nossa hipótese são apenas duas: a informação da posição do ranking e uma medida relacionada à nota dada àquela posição. Neste contexto, gostaria de fazer três observações.

A primeira delas é que a nossa hipótese está relacionada à _diferença na nota para cada posição do ranking entre os dois portais_, e não à diferença na notas de um mesmo título entre os portais. Caso esta última fosse a nossa hipótese de trabalho, precisaríamos juntar as bases título a título - algo que não conseguíriamos fazer bem aqui, uma vez que o nome de alguns títulos mudam um pouquinho do inglês para o português (_e.g._, Projeto Gaia _vs_ Gaia Project). Até existem jeitos de fazer isso, como através das funções dos pacotes `fuzzywuzzyR` - muito parecido com a _lib_ `fuzzywuzzy` do Python - e `stringdist`, mas de fato não é esse o intuito aqui. Além disso, qualquer comparação de notas ao nível do título _per se_ poderia estar confundida com o fato de que alguns deles ou ainda não foram lançados no Brasil ou o foram há muito pouco tempo. Neste caso, poderia ser o caso que a diferença nas notas título a título entre portais estivesse relacionada ao tempo que eles estão circulando nos respectivos mercado, e não necessariamente a uma melhor avaliação.

O segundo ponto está relacionado à medida de nota que vamos usar: a nota do ranking, a nota do usuário ou a quantidade de votos. Seguindo o mesmo raciocínio que no parágrafo anterior, a quantidade de notas deve estar relacionada não só à popularidade do título, mas também à quantidade de tempo que ele esteve ali no portal para ser votado; logo, esta não é uma medida muito interessante para endereçar nossa hipótese (além de não falar de forma direta com ela, né). A outra medida é a nota do ranking, que é a nota que posiciona cada título no ranking. Esta nota é uma média bayesiana^[Existe uma excelente explicação sobre a média bayesiana, sua utilização para rankear itens e implementação em código em: https://www.algolia.com/doc/guides/solutions/ecommerce/relevance-optimization/tutorials/bayesian-average/], calculada a partir da média aritmética das notas, da quantidade de votos e um fator de ajuste associado aos quantis de distribuição de votos entre os títulos. Com isto, esta estimativa ajuda _e.g._ a remover potenciais viéses associados à títulos que recebem pouquíssimos votos, mas notas altas - esta é uma das propriedades que torna este tipo de média atrativa para rankear itens. Assim, como esta medida leva em consideração a quantidade de votos, de títulos e a interação entre estes dois, também não é a medida que estamos buscando. Com isto, chegamos à medida que de fato queremos e vamos utilizar: a nota média dada pelos usuários.

A última coisa que é importante pontuar é que apesar da base de dados do ranking do BGG conter `r format(x = nrow(bgg), big.mark = '.', decimal.mark = ',')` títulos, apenas `r format(x = nrow(tidyr::drop_na(bgg, rank, nota_usuarios)), big.mark = '.', decimal.mark = ',')` deles têm a informação de notas. Além disso, este número ainda é muito maior do que o de títulos na base de dados da Ludopedia - `r format(x = nrow(ludopedia), big.mark = '.', decimal.mark = ',')` jogos. Isto ocorre por que o ranking do BGG parece trazer __todos__ os jogos cadastrados no banco de dados deles, enquanto o da Ludopedia apenas aqueles que foram rankeados. Neste contexto, vamos precisar focar apenas nas posições do ranking em comum entre as duas bases de dados.

Com isto em mente, vamos separar os dados que precisamos. O código abaixo cuida de juntar as duas bases usando a posição do ranking como chave primária, além de selecionar apenas a coluna de nota média, renomeá-la de acordo com a fonte de dados e remover as linhas com `NA` dos dados do ranking do BGG antes de juntá-las. Note que juntaremos as duas bases usando um `inner_join`, com os dados da Ludopedia no `left` e do BGG no `right`, a fim de que tenhamos uma base com as posições do ranking que ocorrem no primeiro __e__ no segundo `tibble`.

```{r junta_ranks}
# usando um inner_join para juntar as posicoes que existem na pagina da ludopedia
ranks <- inner_join(
  # ludopedia no left
  x = ludopedia %>% 
    # selecionando e renomeando colunas
    select(ranking, ludopedia = nota_media),
  # bgg no right
  y = bgg %>% 
    # selecionando e renomeando colunas
    select(rank, bgg = nota_usuarios) %>% 
    # dropando os NAs
    drop_na(),
  # juntando pela coluna de ranking em cada base
  by = c('ranking' = 'rank')
)
rmarkdown::paged_table(x = ranks)
```

# Como as notas estão distribuídas entre nos entre os portais?

Uma vez que tenhamos as duas informações juntas, podemos começar a entender os dados com o foco na hipótese que queremos testar. A primeira coisa que podemos ver abaixo é que parece existir uma relação entre entre as notas dos dois portais, de forma que as notas do ranking no portal da Ludopedia parecem ser consistentemente maiores do que àquelas no BGG (_i.e._, os pontos na figura parecem estar majoritamente acima da linha vermelha de 1:1). Outro ponto importante nesta figura é que parece existir uma diferença na distribuição das notas entre os dois portais: (a) as notas seguem uma distribuição bem mais próxima de uma normal no BGG do que na Ludopedia e (b) a distribuição das notas da Ludopedia tem um _skew_ negativo (_i.e._, muitas notas altas e algumas poucas notas baixas - mediana maior que a média da distribuição), enquanto o do BGG é um pouco mais positivo.

```{r figura_relacao, layout = 'l-body-outset', dpi=200, fig.height=5, code_folding = TRUE}
## criando a figura da relação entre as notas nos dois portais
ggplot(data = ranks, mapping = aes(x = bgg, y = ludopedia)) +
  geom_point(alpha = 0.4, size = 1.5, color = 'black') +
  geom_abline(slope = 1, intercept = 0, size = 0.8, color = 'tomato') +
  geom_xsidehistogram(color = 'black', fill = 'dodgerblue') +
  geom_ysidehistogram(color = 'black', fill = 'mediumseagreen') +
  scale_x_continuous(breaks = seq(from = 3, to = 9.5, by = 0.5)) +
  scale_xsidey_continuous(breaks = NULL) +
  scale_y_continuous(breaks = seq(from = 3, to = 9.5, by = 1)) +
  scale_ysidex_continuous(breaks = NULL) +
  labs(
    title    = 'Relação entre a nota média para uma mesma posição do ranking entre os dois portais',
    subtitle = 'A linha vermelha representa a relação 1:1 entre as notas. Pontos acima da curva representam notas que tendem a ser 
maiores na Ludopedia do que no BGG - e o contrário para os pontos abaixo da curva. Os histogramas nas laterais da figura 
representam a distribuição dos valores das notas para os dados da Ludopedia (em verde) e BGG (em azul).',
    x        = 'BoardGameGeek',
    y        = 'Ludopedia'
  )
```

Um outro padrão interessante é que a diferença nas notas entre os portais parece variar ao longo do ranking: (a) os jogos posicionados até o Top 200 parecem receber consistentemente notas maiores na Ludopedia do que no BGG, (b) aqueles entre o Top 200 e o Top 2100 tendem à receber notas maiores na Ludopedia também (embora hajam muitas exceções) e (c) os jogos posicionados mais ao final do ranking recebem notas consistentemente piores na Ludopedia do que no BGG. Parece que quando o jogo não é bem avaliado, os ~brasileiros~ usuários do portal da Ludopedia tendem à avaliá-los muito mal mesmo. De uma forma ou de outra, podemos ver que a distribuição da diferença entre notas tende a ficar majoritamente acima do valor 0, o que reforça o padrão observado até aqui de que as notas dadas aos jogos que acabam estando no ranking na Ludopedia tendem a ser maiores do que no BGG.

```{r figura_posicao_ranking, layout = 'l-body-outset', dpi=200, fig.height=4, code_folding = TRUE}
# criando a figura para mostrar a variação na diferença entre notas de acordo com o ranking
ranks %>% 
  # calculando a coluna de diferenca
  mutate(
    diferenca = ludopedia - bgg
  ) %>% 
  # calculando a figura da diferenca pela posicao no ranking
  ggplot(mapping = aes(x = ranking, y = diferenca)) +
  geom_line(color = 'grey30') +
  geom_hline(yintercept = 0, size = 1, color = 'tomato') +
  scale_x_continuous(breaks = seq(from = 0, to = nrow(ranks), by = 300)) +
  scale_y_continuous(breaks = seq(from = -4, to = 3, by = 1)) +
  labs(
    title    = 'Diferença entre as notas de acordo com a posição no ranking',
    subtitle = 'Valores negativos indicam que a nota para àquela posição do ranking no portal do BGG é maior que àquela na Ludopedia, 
e o contrário para valores positivos. A linha vermelha marca o valor onde esta diferença é zero.',
    x        = 'Posição no Ranking',
    y        = 'Diferença entre notas (Ludopedia - BGG)'
  )
```

Finalmente, olhando a distribuição da diferença entre as notas, também podemos ver que existe uma tendência de que as notas da Ludopedia sejam maiores do que àquelas do BGG - ainda que hajam algumas exceções. Dado os padrões observados até aqui, é muito claro que existe uma diferença entre os dois portais quanto às notas para uma mesma posição do ranking, com as notas na Ludopedia normalmente sendo maiores que as do BGG. Apesar de não precisamos usar nenhuma análise estatística para constatar isto, vou fazer o exercício aqui usando as funções do pacote `infer` e, só para servir de _benchmark_, as funções equivalentes no pacote `stats` do R.

```{r figura_distribuicao, layout = 'l-body-outset', dpi=200, fig.height=4, code_folding = TRUE}
# criando figura para mostrar o histograma de distribuição da diferença entre as notas
ranks %>% 
  # calculando a coluna de diferenca
  mutate(diferenca = ludopedia - bgg) %>% 
  # criando o histograma de distribuição da diferença de notas
  ggplot(mapping = aes(x = diferenca)) +
  geom_histogram(color = 'black', fill = 'grey80') +
  scale_x_continuous(breaks = seq(from = -4, to = 3, by = 1)) +
  labs(
    title    = 'Distribuição da diferença entre notas para uma mesma posição do ranking',
    subtitle = 'Valores negativos indicam que a nota para àquela posição do ranking no portal do BGG é maior que àquela na Ludopedia, 
e o contrário para valores positivos',
    x        = 'Diferença entre notas (Ludopedia - BGG)',
    y        = 'Observações'
  )
```

# As notas são similares entre portais?

## `stats`

A pergunta principal que propus foi se existiria alguma diferença entre as notas associadas à uma mesma posição entre os rankings da Ludopedia e do BGG. A hipótese estatística aqui seria a de que a diferença média entre as duas notas seria igual a zero; posto de outra forma, a diferença entre cada par de notas associada à cada uma das posições do ranking de _i_ à `r nrow(ranks)` tenderia à zero. Vou tomar isso como a hipótese nula, e considerar como hipótese alternativa que a diferença média entre as notas não é zero. Finalmente, precisamos levar em consideração o fato de que a variância entre as notas na Ludopedia é diferente daquela no BGG também (`r round(x = var(ranks$ludopedia), digits = 4)` _vs_ `r round(x = var(ranks$bgg), digits = 4)`, respectivamente). Com isto em mente, a análise estatística que vamos utilizar é um teste-t pareado bicaudal com variâncias diferentes - implementando abaixo usando a função `stats::t.test`.

```{r test_t_base_r}
# teste-t pareado com variancias diferentes conforme disponivel no base R
t_test_stats <- t.test(x = ranks$ludopedia, y = ranks$bgg, 
                       alternative = 'two.sided', paired = TRUE, var.equal = FALSE)
t_test_stats
```

O resultado desta análise sugere que devemos rejeitar a hipótese nula, sugerindo que a diferença média entre as notas da Ludopedia e do BGG para uma mesma posição do ranking não tende à zero. Na realidade, podemos ver que a estimativa da diferença média estimada entre as notas é de `r round(x = t_test_stats$estimate[[1]], digits = 3)`, com um intervalo de confiança de 95% de `r round(x = t_test_stats$conf.int[[1]], digits = 3)` à `r round(x = t_test_stats$conf.int[[2]], digits = 3)`. Isto seria o tanto que as notas do ranking da Ludopedia superam àquelas do BGG, em média. Vamos agora examinar o que o pacote `infer` nos oferece.

## `infer`

De acordo com o próprio site^[https://infer.netlify.app/index.html], o `infer` tem por objetivo implementar a inferência estatística utilizando uma gramática estatística expressiva que seja coerente com o framework existente no `tidyverse`. Esse pacote traz algumas funções para atingir este objetivo e, através de sua documentação, podemos ver que a análise acaba ficando bastante verbosa - mas bem aderente às idéia e conceitos da estatística inferencial. Assim, vamos reproduzir o teste-t acima usando os equivalentes existentes dentro do `infer`.

Vamos iniciar a análise carregando o pacote e, então, adicionando uma coluna no `tibble` original com a diferença par a par entre as notas já calculada. Precisamos fazer isso pois o `infer` não possui uma implementação explícita do test-t pareado, de forma que, dentro deste framework, ele se torna equivalente a um teste-t univariado sobre as diferenças entre pares de valores. Uma vez que tenhamos esta diferença calculada, usamos os verbos do `infer`  para especificar (`specify`) a variável resposta e calcular a estatística de teste que vamos usar (`calculate`). Nesta hora é que deveríamos especificar que a estatística que vamos usar é a distribuição t, e definir que a hipótese nula é de que as diferença média é igual a zero. No entanto, vou fugir um pouco de focar no teste-t _per se_ e usar uma outra funcionalidade do pacote: a facilidade com a qual podemos fazer inferências utilizando técnicas de reamostragem para testar uma hipótese nula.

Técnicas de reamostragem são uma ferramenta muito útil em diversas situações, especialmente quando não sabemos a que família de distribuição estatística a variável resposta e/ou seus resíduos pertencem e precisamos fazer uma inferência ou estimar intervalos de confiança. Também existem outros casos para a sua aplicação, como quando temos uma hipótese específica sobre o processo gerador dos dados e queremos testá-lo explicitamente ou realizar comparações entre duas populações e temos um número diferente de amostras entre elas. Vou seguir o padrão aqui, e utilizar esta técnica para fazer a inferência sobre a diferença média entre as notas e estimar o intervalo de confiança desta diferença. Para tal, utilizei o _bootstrap_, que é uma implementação da reamostragem através da qual criamos _n_ conjuntos de dados, cada um dos quais criado através de amostras tomadas com substituição a partir do conjunto de dados original (_i.e._, uma mesma observação pode aparecer mais de uma vez em um mesmo conjunto de dados). A partir dos conjunto de dados reamostrados calculamos alguma estatística de interesse para chegar ao nosso objetivo.

Para implementar esta reamostragem, vou então extrair a diferença média entre as notas no nosso conjunto de dados original. Para isso, passaremos o a string `mean` para o argumento `stat` da função `infer::calculate`, e usar um `purrr::pull` para extrair o valor da estatística de interesse como um vetor com um elemento.

```{r obs_moment}
library(infer) # para fazer o teste de hipótese

# colocando a diferenca no tibble
ranks <- ranks %>% 
  # calculando a coluna de diferenca
  mutate(
    diferenca = ludopedia - bgg
  )

# rodando um teste-t pareado original
obs_statistic <- ranks %>% 
  # especificando a variável analisada para o infer
  specify(
    response = diferenca
  ) %>% 
  # calculando estatistica de teste
  calculate(stat = 'mean') %>% 
  # extraindo a coluna com a estatistica
  pull(stat)
obs_statistic
```

A próxima coisa que farei será calcular o intervalo de confiança para àquela estimativa. Para tal, vamos gerar 1000 conjuntos de dados reamostrados com substituição (através do verbo `generate`) e calcular o valor da média de cada um deles. Com isso, vamos construir uma distribuição de frequência das médias obtidas através da reamostragem e extrair os valores que estejam nos extremos do percentil de 95% desta distribuição (através da função `infer::get_confidence_interval`). Como podemos ver, tanto a estimativa quanto o intervalo de confiança que obtivemos são similares aqueles reportados pelo `stats::t.test`.

```{r bootstrap_ci}
## criando reamostragem para estimar o intervalo de confiança
boot_ci_tbl <- ranks %>% 
  # especificando a variável analisada para o infer
  specify(
    response = diferenca
  ) %>% 
  # gerando bootstrap
  generate(reps = 1000, type = 'bootstrap') %>% 
  # calculando estatistica do bootstrap
  calculate(stat = 'mean')

## criando o histograma de distribuição de frequência da médias
ggplot(data = boot_ci_tbl, mapping = aes(x = stat)) +
  geom_histogram(color = 'black', fill = 'grey80') +
  scale_x_continuous(n.breaks = 8) +
  labs(
    title = 'Distribuição de frequência da diferença média entre notas nos dados reamostrados',
    x     = 'Diferença média entre as notas (Ludopedia - BGG)',
    y     = 'Frequência'
  )

## calculando o intervalo de confiança
boot_ci <- boot_ci_tbl %>% 
  # pegando o intervalo de confianca
  get_confidence_interval(type = 'percentile')
boot_ci
```

Também podemos calcular a distribuição nula da diferença média entre notas através do _bootstrap_. `hypothesize`

```{r null_moment}
## calculando a distribuicao da estatistica de teste com o bootstrap
null_statistic <- ranks %>% 
  # especificando a variável analisada para o infer
  specify(
    response = diferenca
  ) %>% 
  # especificando a hipotese nula que queremos testar
  # não existe diferença entre as notas medias para uma mesma posicao entre rankins
  hypothesize(null = 'point', mu = 0) %>%
  # gerando bootstrap
  generate(reps = 500, type = 'bootstrap') %>% 
  # calculando estatistica do bootstrap
  calculate(stat = 'mean')
null_statistic
```

`visualize`, `shade_confidence_interval`, `shade_p_value`

```{r visualiza_infer, layout = 'l-body-outset', fig.height=3, dpi = 200, code_folding = TRUE}
null_statistic %>% 
  # criando a visualização
  visualize() +
  # sombreando o intervalo de confianca
  shade_confidence_interval(endpoints = boot_ci, color = 'white', fill = 'tomato') +
  # colocar uma linha para a estimativa
  shade_p_value(obs_stat = obs_statistic, direction = 'two-sided', color = 'tomato', size = 1) +
  # ediitando a figura
  scale_x_continuous(breaks = seq(from = -0.05, to = 0.4, by = 0.05)) +
  labs(
    title    = 'Distribuição dos valores nulos e observados',
    subtitle = 'O histograma representa a distribuição dos valores da diferença entre médias de acordo com a hipótese nula. A linha
vertical vermelha indica a estimativa da diferença média entre as notas, enquanto a barra vertical o intervalo de
confiança 95%. Como não há sobreposição entre a distribuição dos dados de acordo com a hipótese nula e o intervalo de
confiança, devemos rejeitar a hipótese nula.',
    caption  = 'Utilizamos o método de reamostragem por bootstrap para a estimativa do intervalo de confiança, onde o calculamos através do percentil de distribuição das médias reamostradas.',
    x        = 'Diferença entre médias (Ludopedia - BGG)',
    y        = 'Frequência'
  )
```

## Subamostragem

Cria função para fazer a reamostragem.

```{r funcao_reamostragem}
# criando funcao para fazer a reamostragem
create_sample <- function(dataset, tamanho, substituicao = FALSE) {
  dataset %>% 
    # retira uma amostra aleatoria de um determinado tamanho
    sample_n(size = tamanho, replace = substituicao)
}
```

Rodando a reamostragem.

```{r cria_dataset_reamostrado}
## criando dataframe reamostrado
reamostragem <- rerun(.n = 500,
                      # rodando a funcao para criar amostrar 500 vezes, cada uma das quais amostrando
                      # 50 observacoes aleatoriamente
                      create_sample(dataset = ranks, tamanho = 50, substituicao = FALSE)) %>% 
  # juntando cada um dos dataframes e adicioando um sample id
  bind_rows(.id = 'sample_id') %>% 
  # aninhando o dataframe com os dados que vamos usar para ajustar o test-t dentro de cada sample_id
  nest(data = -sample_id)
```

Rodando o test-t e extraindo os resultados

```{r ajusta_reamostragem}
resultados_reamostragem <- reamostragem %>% 
  mutate(
    # aplicando um teste-t pareado às amostras de cada sample_id
    test_t = map(.x = data, 
                 .f = ~t.test(x = .x$ludopedia, y = .x$bgg, 
                              alternative = 'two.sided', paired = TRUE, var.equal = FALSE)
    ),
    # extraindo as informacoes tidy do ajuste do test-t pareado
    tidy_t = map(.x = test_t, .f = broom::tidy)
  ) %>% 
  # desaninhando os resultados do test-t
  unnest(tidy_t) %>% 
  # jogando fora alguma colunas que nao precisaremos mais
  select(-data, -test_t)
resultados_reamostragem
```

Plotando os resultados da reamostragem.

```{r figura_reamostragem, layout = 'l-body-outset', dpi=200, fig.height=4, code_folding = TRUE}
# pegando os quantis da distribuicao das estimativas das subamostras
quantis_subamostra <- quantile(x = resultados_reamostragem$estimate, probs = c(0.025, 0.975))
media_subamostra <- mean(x = resultados_reamostragem$estimate)

## pegando os dados do que o density plot vai usar e retendo apenas as areas
## que estao fora do quantil
df_dos_quantis <- tibble(
  # pegando os valores de x e y que serão usados para o density plot
  x = density(x = resultados_reamostragem$estimate)$x,
  y = density(x = resultados_reamostragem$estimate)$y
) %>% 
  mutate(
    # sinalizando os valores de x que estão fora do quantil de 95%
    lower_quantile = x < quantis_subamostra[1],
    upper_quantile = x > quantis_subamostra[2]
  ) %>% 
  # filtrando apenas as observacoes que estao fora do quantil
  filter(lower_quantile | upper_quantile)

# criando a figura
resultados_reamostragem %>% 
  ggplot(mapping = aes(x = estimate)) +
  geom_density(fill = 'grey80', color = 'black') +
  geom_ribbon(data = filter(df_dos_quantis, lower_quantile),
              mapping = aes(x = x, ymin = 0, ymax = y), fill = 'tomato') +
  geom_ribbon(data = filter(df_dos_quantis, upper_quantile),
              mapping = aes(x = x, ymin = 0, ymax = y), fill = 'tomato') +
  geom_vline(xintercept = 0, color = 'black', alpha = 0.6) +
  geom_vline(xintercept = media_subamostra, color = 'black', linetype = 2) +
  labs(
    title    = 'As notas do ranking da Ludopedia são maiores que as do BoardGameGeek',
    subtitle = str_glue('A estimativa da diferença através da subamostragem é de que as notas da Ludopedia superam as do BoardGameGeek\nem {round(media_subamostra, digits = 2)} pontos (Intervalo de Confiança: {round(quantis_subamostra[1], digits = 2)} à {round(quantis_subamostra[2], digits = 2)} pontos)'),
    caption  = 'A área cinza representa o intervalo de confiança de 95% da estimativa da diferença nas notas entre os\ndois portais, obtidas através de 500 estimativas independentes tomadas a partir de 50 amostras aleatórias dos dados.',
    x        = 'Diferença entre as notas do ranking da Ludopedia e do BoardGameGeek',
    y        = 'Densidade'
  ) +
  theme(axis.title.y = element_blank())
```

## A milha extra

Ajusta MARS para extrair o hinge.

```{r ajusta_mars}
# carregando o tidymodels 
library(tidymodels)

# ajustando um MARS aos dados, forcando apenas 2 termos
modelo <- mars(mode = 'regression', num_terms = 2) %>% 
  set_engine(engine = 'earth') %>% 
  fit(diferenca ~ ranking, data = ranks)

# sumario do modelo
summary(modelo$fit)
```

Extrai o hinge.

```{r extrai_hinge}
ponto_de_corte <- modelo$fit$coefficients %>% 
  # pegando o nome das linhas
  rownames %>% 
  # pegando o segundo elemento - nome do coeficiente da funcao hinge
  pluck(2) %>% 
  # extraindo todos os numeros do string
  str_extract(pattern = '[0-9]+') %>% 
  # parseando a string para numeric
  parse_number()
ponto_de_corte
```

Cria funcao de reamostragem extratificada.

```{r funcao_reamostragem_estratificada}
# criando funcao para fazer a reamostragem
create_stratified_sample <- function(dataset, tamanho, substituicao = FALSE,...) {
  dataset %>% 
    # agrupa de acordo com o teste logico que for passado em ...
    group_by(...) %>% 
    # retira uma amostra aleatoria de um determinado tamanho de cada grupo 
    sample_n(size = tamanho, replace = substituicao) %>% 
    # desagrupa o dataframe
    ungroup
}
```

Roda a funcao de reamostragem estratificada

```{r cria_dataset_reamostrado_estratificado}
## criando dataframe reamostrado
reamostragem_estratificada <- rerun(.n = 500,
                                    # rodando a funcao para criar amostrar 500 vezes, cada
                                    # uma das quais amostrando 50 observacoes aleatoriamente
                                    create_stratified_sample(dataset = ranks, tamanho = 50, 
                                                             substituicao = FALSE,
                                                             ranking <= ponto_de_corte)) %>% 
  # juntando cada um dos dataframes e adicioando um sample id
  bind_rows(.id = 'sample_id') %>% 
  # renomeando a coluna de estratificacao
  rename(estratificacao = `ranking <= ponto_de_corte`) %>% 
  # aninhando o dataframe com os dados que vamos usar para ajustar o test-t dentro de cada sample_id
  nest(data = -c(sample_id, estratificacao))
```

Ajustando a reamostragem estratificada.

```{r ajusta_reamostragem_estratificada}
resultados_reamostragem_estratificada <- reamostragem_estratificada %>% 
  mutate(
    # aplicando um teste-t pareado às amostras de cada sample_id
    test_t = map(.x = data, 
                 .f = ~t.test(x = .x$ludopedia, y = .x$bgg, 
                              alternative = 'two.sided', paired = TRUE, var.equal = FALSE)
    ),
    # extraindo as informacoes tidy do ajuste do test-t pareado
    tidy_t = map(.x = test_t, .f = broom::tidy)
  ) %>% 
  # desaninhando os resultados do test-t
  unnest(tidy_t) %>% 
  # jogando fora alguma colunas que nao precisaremos mais
  select(-data, -test_t)
resultados_reamostragem_estratificada
```

Plota figura do resultado.

```{r figura_reamostragem_estratificada, layout = 'l-body-outset', dpi=200, fig.height=4, code_folding = TRUE}
# criando a figura
resultados_reamostragem_estratificada %>% 
  # estilizando o texto que aparecerá no eixo y
  mutate(
    estratificacao = ifelse(test = estratificacao, 
    yes = str_glue('Até a {ponto_de_corte}º posição'), 
    no = str_glue('Acima da {ponto_de_corte}º posição'))
  ) %>% 
  # plotando a figura
  ggplot(mapping = aes(x = estimate, y = estratificacao, fill = factor(stat(quantile)))) +
  stat_density_ridges(geom = 'density_ridges_gradient', scale = 0.95, 
                      calc_ecdf = TRUE, quantiles = c(0.025, 0.975), 
                      show.legend = FALSE) +
  scale_fill_manual(values = c('tomato', 'grey80', 'tomato')) +
  geom_vline(xintercept = 0, color = 'black', alpha = 0.5) +
  labs(
    title    = 'A diferença na nota entre os dois portais depende da posição do ranking',
    subtitle = str_glue('O ranking da Ludopedia tem notas maiores que aquele do BoardGameGeek para os títulos que ocupem\naté a {ponto_de_corte}º posição, a partir de onde eles passam a ser melhores avaliados neste último'),
    caption  = 'A área cinza representa o intervalo de confiança de 95% da estimativa da diferença nas notas entre os\ndois portais, obtidas através de 500 estimativas independentes tomadas a partir de 50 amostras aleatórias dos dados.',
    x        = 'Diferença entre as notas do ranking da Ludopedia e do BoardGameGeek'
  ) +
  theme(axis.title.y = element_blank())
```

# Conclusões

# Possíveis Extensões
