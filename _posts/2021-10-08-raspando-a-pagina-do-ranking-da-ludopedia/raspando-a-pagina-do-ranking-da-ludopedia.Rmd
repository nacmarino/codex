---
title: "Raspando a Pagina do Ranking da Ludopedia"
description: |
  Eu já havia raspado a página do ranking do BoardGameGeek, e agora eu vou repetir a tarefa focando na página da Ludopedia. Meu objetivo com isso é criar a base para que, mais tarde, possamos fazer análises comparando os jogos e os rankings entre os dois portais.
author:
  - first_name: Nicholas 
    last_name: Marino
    url: https://github.com/nacmarino
date: 10-08-2021
categories:
  - web scraping
  - boardgames
output:
  distill::distill_article:
    self_contained: false
    toc: true
    code_folding: true
    highlight: rstudio
draft: true
---

```{r setup, include=FALSE}
# setando as opções gerais dos code chunks
knitr::opts_chunk$set(echo = FALSE, code_folding = FALSE, fig.align = 'center')

# presetando o ggplot2
library(ggplot2)

# setando o tema geral do ggplot2
theme_set(new = theme_minimal(base_family = 'Roboto'))

# atualizando o tema
theme_update(
  plot.title    = element_text(face = 'bold', size = 10),
  plot.subtitle = element_text(size = 8),
  plot.caption  = element_text(size = 8),
  axis.title    = element_text(face = 'bold', size = 8),
  axis.text     = element_text(color = 'black', size = 8),
  strip.text    = element_text(face = 'bold', size = 8)
)
```

# Motivação

# Raspando o Ranking

```{r carrega_pacotes}
library(tidyverse) # core
library(httr) # web scrapping
library(xml2) # parsear
library(fs) # mexer com paths
library(knitr) # para embbedar as figuras
```

## Identificar

blablabla

```{r imagem_identificar, layout = 'l-body-outset', code_folding = TRUE}
include_graphics(path = 'images/imagem_1.jpg')
```

## Navegar

blablabla

```{r imagem_navegar, layout = 'l-body-outset', code_folding = TRUE}
include_graphics(path = 'images/imagem_2.jpg')
```

## Replicar

blablabla

```{r replicar}
## url base do ranking
base_url <- 'https://www.ludopedia.com.br/ranking?pagina='

# fazendo o GET
resultado <- GET(url = str_glue(base_url, 1))
resultado
```

## Parsear

blablala

```{r parser_capa, fig.width=6}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando a imagem da capa
  xml_find_all(xpath = '//img[@class="img-capa"]') %>% 
  # pegando o url
  xml_attr(attr = 'src') %>% 
  # pegando a primeira observação
  head(1) %>% 
  # plotando a imagem de uma capa
  magick::image_read() %>% 
  # aumentando a resolução da imagem
  magick::image_scale(geometry = '300')
```

blablabla

```{r parser_link_jogo}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando o conteudo do titulo do mini-box
  xml_find_all(xpath = '//h4[@class="media-heading"]') %>% 
  # pegando todos os links
  xml_find_all(xpath = 'a') %>% 
  # extraindo o atributo dos hiperlinks
  xml_attr(attr = 'href') %>% 
  # pegando algumas instancias apenas
  head()
```

blablabla

```{r parser_ranking}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando o conteudo do titulo do mini-box
  xml_find_all(xpath = '//h4[@class="media-heading"]') %>% 
  # pegando o ranking
  xml_find_all(xpath = 'span[@class="rank"]') %>% 
  # pegando o texto
  xml_text() %>% 
  # pegando algumas instancias apenas
  head()
```

blablabla

```{r parser_nome}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando o conteudo do titulo do mini-box
  xml_find_all(xpath = '//h4[@class="media-heading"]') %>% 
  # pegando o nome do jogo
  xml_find_all(xpath = 'a[@title]') %>% 
  # pegando o texto
  xml_text() %>% 
  # pegando algumas instancias apenas
  head()
```

blablabla

```{r parser_ano}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando o conteudo do titulo do mini-box
  xml_find_all(xpath = '//h4[@class="media-heading"]') %>% 
  # pegando o ano de lançamento do jogo
  xml_find_all(xpath = 'small') %>% 
  # pegando o texto
  xml_text() %>% 
  # pegando algumas instancias apenas
  head()
```


blablabla

```{r parser_notas}
resultado %>% 
  # pegando o conteudo
  content() %>% 
  # pegando o conteudo do titulo do mini-box
  xml_find_all(xpath = '//h4[@class="media-heading"]') %>% 
  # pegando as notas do jogo
  xml_find_all(xpath = '//div[@class="rank-info"]') %>% 
  # pegando o texto
  xml_text() %>% 
  # pegando algumas instancias apenas
  head() %>% 
  # tirando um pouco o excesso de whitespace
  str_squish()
```

## Validar

blablabla

```{r funcoes_validar}
# função para fazer o GET
pega_pagina <- function(url_base, pagina, save_dir) {
  ## junta a base url com o numero da pagina e salva no diretorio alvo
  GET(url = str_glue(url_base, pagina), 
      write_disk(path = sprintf(fmt = '%s/pagina_%03d.html', save_dir, pagina), 
                 overwrite = TRUE)
  )
  
  # esperanando antes de prosseguir
  Sys.sleep(runif(n = 1, min = 1, max = 5))
}

# função para parsear uma pagina
parser_pagina <- function(path_to_html){
  
  ## lendo a pagina raspada
  pagina_raspada <- read_html(x = path_to_html)
  
  ## infos do heading
  media_head <- pagina_raspada %>% 
    xml_find_all(xpath = '//h4[@class="media-heading"]')
  
  ## link para a imagem da capa
  links_da_capa <- pagina_raspada %>% 
    xml_find_all(xpath = '//img[@class="img-capa"]') %>% 
    xml_attr(attr = 'src')
  
  ## link para a pagina do jogo
  link_jogo <- media_head %>% 
    xml_find_all(xpath = 'a') %>% 
    xml_attr(attr = 'href')
  
  ## posicao do ranking de cada titulo
  posicao_ranking <- media_head %>% 
    xml_find_all(xpath = 'span[@class="rank"]') %>% 
    xml_text()
  
  ## nome do jogo
  titulo_jogo <- media_head %>% 
    xml_find_all(xpath = 'a[@title]') %>% 
    xml_text()
  
  ## ano de lancamento do jogo
  ano_jogo <- media_head %>% 
    xml_find_all(xpath = 'small') %>% 
    xml_text()
  
  ## informacoes gerais das notas
  notas_jogo <- pagina_raspada %>% 
    xml_find_all(xpath = '//div[@class="rank-info"]') %>% 
    xml_text()
  
  ## colocando rsultados numa tibble
  tibble(
    ranking   = posicao_ranking, 
    titulo    = titulo_jogo, 
    ano       = ano_jogo, # 
    notas     = notas_jogo,
    link_capa = links_da_capa,
    link_jogo = link_jogo
  )
}
```

blablabla

```{r validar_pagina_2}
# pegando a segunda pagina do ranking
pega_pagina(url_base = base_url, pagina = 2, save_dir = 'data/')

# checando para ver se o html foi baixado
dir_ls(path = 'data/')
```

blablabla

```{r parser_pagina_2}
parser_pagina(path_to_html = dir_ls(path = 'data/', regexp = 'html'))
```

## Iterar

blablabla

```{r imagem_iterar, layout = 'l-body-outset', code_folding = TRUE}
include_graphics(path = 'images/imagem_3.jpg')
```

blablabla

```{r funcao_ultima_pagina}
# função para definir o número máximo de páginas para raspar
pega_max_paginas <- function(url_base) {
  GET(url = str_glue(url_base, 1)) %>% 
    # pegando o conteudo do GET
    content() %>% 
    # pegando o xpath da paginacao
    xml_find_all(xpath = '//ul[@class="pagination"]//a[@title="Última Página"]') %>% 
    # pegando o link que contem o numero da pagina maxima
    xml_attr('href') %>% 
    # pegando o numero da pagina
    str_extract(pattern = '(?<=pagina=)([0-9]+)') %>% 
    # parseando para numero
    parse_number()
}

## definindo qual o numero maximo de paginas para pegar
ultima_pagina <- pega_max_paginas(url_base = base_url)
ultima_pagina
```

blablabla

```{r itera_exemplo}
## pegando as paginas
walk(
  .x = 1:5,
  # .x = 1:ultima_pagina, # descomentar essa linha se for para raspar tudo
  .f = pega_pagina,
  url_base = base_url, save_dir = 'data/'
)
```

## Faxinar

blablabla

```{r parser_paginas_todas, layout = 'l-page'}
## pegando o path para as paginas
path_das_paginas <- dir_ls(path = 'data/', regexp = 'html')

## colocando todas as tabelas em um dataframe so
df <- map_dfr(.x = path_das_paginas, .f = parser_pagina)
rmarkdown::paged_table(x = df)
```

blablabla

```{r faxina_paginas, layout = 'l-page'}
df <- df %>% 
  mutate(
    # parseando o ranking para numerico
    ranking = parse_number(ranking),
    # tratando o string titulo do jogo
    titulo  = str_squish(string = titulo),
    # parseando o ano para numerico
    ano     = parse_number(ano),
    # ajustando a string do campo de nota
    notas   = str_squish(string = notas),
  ) %>% 
  # separando a coluna com as informacoes de nota atraves do padrao da barra
  separate(col = notas, into = c('nota_rank', 'nota_media', 'notas', 'leftover'), sep = '\\|') %>% 
  # tratando as informacoes da coluna separada
  mutate(
    # nota do ranking
    nota_rank  = parse_number(nota_rank),
    # nota dos usuarios
    nota_media = parse_number(nota_media),
    # quantidade de notas
    notas      = parse_number(notas) 
  ) %>% 
  # removendo colunas que nao serao mais necessarias
  select(-leftover)
rmarkdown::paged_table(x = df)
```

# De igual para igual?

blablabla

```{r df_ludopedia, layout = 'l-page'}
## lendo os dados raspados da ludopedia
ludopedia <- read_rds(file = 'data/ranking_ludopedia.rds')
rmarkdown::paged_table(x = ludopedia)
```

blablabla

```{r df_bgg, layout = 'l-page'}
## lendo os dados raspados da ludopedia
bgg <- read_rds(file = 'data/ranking_bgg.rds')
rmarkdown::paged_table(x = bgg)
```

blablabla

# Conclusões
